{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 2GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/train\"\n",
    "val_dir = \"../data/val\"\n",
    "test_dir = \"../data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\", index_col=0)\n",
    "val_df = pd.read_csv(\"../data/val.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"../data/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_df, val_df, test_df]\n",
    "result_dfs = []\n",
    "\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df['id'] = df.index\n",
    "    df['id'] = df['id'].apply(lambda x: x+\".jpg\")\n",
    "    result_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = result_dfs[0]\n",
    "val_df = result_dfs[1]\n",
    "test_df = result_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_0</th>\n",
       "      <th>ABS_RX</th>\n",
       "      <th>ABS_Y</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-16_08-59-11-257177</th>\n",
       "      <td>2221.29</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2020-06-16_08-59-11-257177.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16_08-59-12-485854</th>\n",
       "      <td>113.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2020-06-16_08-59-12-485854.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16_08-59-13-612812</th>\n",
       "      <td>115.79</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2020-06-16_08-59-13-612812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16_08-59-14-730263</th>\n",
       "      <td>2219.64</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2020-06-16_08-59-14-730263.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16_08-59-15-971140</th>\n",
       "      <td>177.91</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2020-06-16_08-59-15-971140.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dist_0  ABS_RX  ABS_Y  \\\n",
       "2020-06-16_08-59-11-257177  2221.29    -0.2    0.6   \n",
       "2020-06-16_08-59-12-485854   113.47     1.0    0.6   \n",
       "2020-06-16_08-59-13-612812   115.79    -0.9    0.6   \n",
       "2020-06-16_08-59-14-730263  2219.64    -0.9    0.6   \n",
       "2020-06-16_08-59-15-971140   177.91     0.1    0.6   \n",
       "\n",
       "                                                        id  \n",
       "2020-06-16_08-59-11-257177  2020-06-16_08-59-11-257177.jpg  \n",
       "2020-06-16_08-59-12-485854  2020-06-16_08-59-12-485854.jpg  \n",
       "2020-06-16_08-59-13-612812  2020-06-16_08-59-13-612812.jpg  \n",
       "2020-06-16_08-59-14-730263  2020-06-16_08-59-14-730263.jpg  \n",
       "2020-06-16_08-59-15-971140  2020-06-16_08-59-15-971140.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2156 validated image filenames.\n",
      "Found 300 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df, directory=train_dir, \n",
    "                                              x_col=\"id\", y_col=\"ABS_RX\",\n",
    "                                              class_mode=\"other\", # \"categorical\"\n",
    "                                              target_size=(224, 224), \n",
    "                                              batch_size=32)\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df, directory=val_dir, \n",
    "                                              x_col=\"id\", y_col=\"ABS_RX\", \n",
    "                                              class_mode=\"other\", target_size=(224, 224), \n",
    "                                              batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights=\"../models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 36,433,025\n",
      "Trainable params: 12,845,313\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",\n",
    "              optimizer=optimizers.RMSprop(lr=0.0001))\n",
    "              #metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "67/67 [==============================] - 18s 266ms/step - loss: 4.1552 - val_loss: 0.2935\n",
      "Epoch 2/200\n",
      "67/67 [==============================] - 17s 261ms/step - loss: 0.2925 - val_loss: 0.2376\n",
      "Epoch 3/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2909 - val_loss: 0.2168\n",
      "Epoch 4/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2683 - val_loss: 0.1946\n",
      "Epoch 5/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2553 - val_loss: 0.1952\n",
      "Epoch 6/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2576 - val_loss: 0.1965\n",
      "Epoch 7/200\n",
      "67/67 [==============================] - 17s 261ms/step - loss: 0.2493 - val_loss: 0.1698\n",
      "Epoch 8/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.2395 - val_loss: 0.1643\n",
      "Epoch 9/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2408 - val_loss: 0.1597\n",
      "Epoch 10/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2397 - val_loss: 0.1815\n",
      "Epoch 11/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.2429 - val_loss: 0.1542\n",
      "Epoch 12/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2285 - val_loss: 0.1601\n",
      "Epoch 13/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.2311 - val_loss: 0.1778\n",
      "Epoch 14/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2287 - val_loss: 0.1570\n",
      "Epoch 15/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2172 - val_loss: 0.1614\n",
      "Epoch 16/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2234 - val_loss: 0.1899\n",
      "Epoch 17/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.2205 - val_loss: 0.1804\n",
      "Epoch 18/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2176 - val_loss: 0.1555\n",
      "Epoch 19/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2225 - val_loss: 0.1516\n",
      "Epoch 20/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2184 - val_loss: 0.1507\n",
      "Epoch 21/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2132 - val_loss: 0.1662\n",
      "Epoch 22/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2171 - val_loss: 0.1595\n",
      "Epoch 23/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2066 - val_loss: 0.1417\n",
      "Epoch 24/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2182 - val_loss: 0.1514\n",
      "Epoch 25/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2117 - val_loss: 0.1597\n",
      "Epoch 26/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2152 - val_loss: 0.1475\n",
      "Epoch 27/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2160 - val_loss: 0.1490\n",
      "Epoch 28/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2099 - val_loss: 0.1443\n",
      "Epoch 29/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.2077 - val_loss: 0.1689\n",
      "Epoch 30/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2129 - val_loss: 0.1437\n",
      "Epoch 31/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2052 - val_loss: 0.1457\n",
      "Epoch 32/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2116 - val_loss: 0.1433\n",
      "Epoch 33/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2104 - val_loss: 0.2135\n",
      "Epoch 34/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2088 - val_loss: 0.1731\n",
      "Epoch 35/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.2127 - val_loss: 0.1685\n",
      "Epoch 36/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2083 - val_loss: 0.1456\n",
      "Epoch 37/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2071 - val_loss: 0.1657\n",
      "Epoch 38/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.2026 - val_loss: 0.1518\n",
      "Epoch 39/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2009 - val_loss: 0.1675\n",
      "Epoch 40/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2099 - val_loss: 0.1445\n",
      "Epoch 41/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2024 - val_loss: 0.1835\n",
      "Epoch 42/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2052 - val_loss: 0.1749\n",
      "Epoch 43/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.2074 - val_loss: 0.1473\n",
      "Epoch 44/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2052 - val_loss: 0.1451\n",
      "Epoch 45/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.2049 - val_loss: 0.1425\n",
      "Epoch 46/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.2026 - val_loss: 0.1398\n",
      "Epoch 47/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2028 - val_loss: 0.1819\n",
      "Epoch 48/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.2022 - val_loss: 0.1939\n",
      "Epoch 49/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.2046 - val_loss: 0.1503\n",
      "Epoch 50/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1984 - val_loss: 0.1379\n",
      "Epoch 51/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.2031 - val_loss: 0.1399\n",
      "Epoch 52/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.2002 - val_loss: 0.1389\n",
      "Epoch 53/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.1999 - val_loss: 0.1810\n",
      "Epoch 54/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2008 - val_loss: 0.1452\n",
      "Epoch 55/200\n",
      "67/67 [==============================] - 17s 249ms/step - loss: 0.1989 - val_loss: 0.1463\n",
      "Epoch 56/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.2010 - val_loss: 0.1390\n",
      "Epoch 57/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1973 - val_loss: 0.1420\n",
      "Epoch 58/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.2013 - val_loss: 0.1471\n",
      "Epoch 59/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1994 - val_loss: 0.1405\n",
      "Epoch 60/200\n",
      "67/67 [==============================] - 18s 261ms/step - loss: 0.1958 - val_loss: 0.1458\n",
      "Epoch 61/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1996 - val_loss: 0.1367\n",
      "Epoch 62/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1924 - val_loss: 0.1476\n",
      "Epoch 63/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1943 - val_loss: 0.1366\n",
      "Epoch 64/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1955 - val_loss: 0.1494\n",
      "Epoch 65/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.2055 - val_loss: 0.1407\n",
      "Epoch 66/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1978 - val_loss: 0.1350\n",
      "Epoch 67/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1950 - val_loss: 0.1437\n",
      "Epoch 68/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.2021 - val_loss: 0.1542\n",
      "Epoch 69/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1971 - val_loss: 0.1504\n",
      "Epoch 70/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1966 - val_loss: 0.1625\n",
      "Epoch 71/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1976 - val_loss: 0.1450\n",
      "Epoch 72/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1996 - val_loss: 0.1460\n",
      "Epoch 73/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1999 - val_loss: 0.1343\n",
      "Epoch 74/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1920 - val_loss: 0.1426\n",
      "Epoch 75/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1940 - val_loss: 0.1369\n",
      "Epoch 76/200\n",
      "67/67 [==============================] - 18s 261ms/step - loss: 0.1933 - val_loss: 0.2666\n",
      "Epoch 77/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1939 - val_loss: 0.1595\n",
      "Epoch 78/200\n",
      "67/67 [==============================] - 18s 262ms/step - loss: 0.1920 - val_loss: 0.1353\n",
      "Epoch 79/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1939 - val_loss: 0.1407\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1944 - val_loss: 0.1360\n",
      "Epoch 81/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1952 - val_loss: 0.1370\n",
      "Epoch 82/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.1950 - val_loss: 0.1706\n",
      "Epoch 83/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1967 - val_loss: 0.1423\n",
      "Epoch 84/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1900 - val_loss: 0.1500\n",
      "Epoch 85/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1909 - val_loss: 0.1322\n",
      "Epoch 86/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1940 - val_loss: 0.1258\n",
      "Epoch 87/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1902 - val_loss: 0.1310\n",
      "Epoch 88/200\n",
      "67/67 [==============================] - 18s 262ms/step - loss: 0.1925 - val_loss: 0.1291\n",
      "Epoch 89/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1915 - val_loss: 0.1498\n",
      "Epoch 90/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.1910 - val_loss: 0.1309\n",
      "Epoch 91/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1942 - val_loss: 0.1485\n",
      "Epoch 92/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1920 - val_loss: 0.1580\n",
      "Epoch 93/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1878 - val_loss: 0.1356\n",
      "Epoch 94/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1947 - val_loss: 0.1374\n",
      "Epoch 95/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1936 - val_loss: 0.1381\n",
      "Epoch 96/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1902 - val_loss: 0.1774\n",
      "Epoch 97/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1870 - val_loss: 0.1841\n",
      "Epoch 98/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1942 - val_loss: 0.1324\n",
      "Epoch 99/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1931 - val_loss: 0.1306\n",
      "Epoch 100/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1894 - val_loss: 0.1409\n",
      "Epoch 101/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1947 - val_loss: 0.1267\n",
      "Epoch 102/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1904 - val_loss: 0.1398\n",
      "Epoch 103/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1979 - val_loss: 0.1342\n",
      "Epoch 104/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1929 - val_loss: 0.1538\n",
      "Epoch 105/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1880 - val_loss: 0.1602\n",
      "Epoch 106/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1914 - val_loss: 0.1274\n",
      "Epoch 107/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1916 - val_loss: 0.1269\n",
      "Epoch 108/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1900 - val_loss: 0.1271\n",
      "Epoch 109/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1900 - val_loss: 0.1331\n",
      "Epoch 110/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1925 - val_loss: 0.1448\n",
      "Epoch 111/200\n",
      "67/67 [==============================] - 18s 262ms/step - loss: 0.1873 - val_loss: 0.1258\n",
      "Epoch 112/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1885 - val_loss: 0.1369\n",
      "Epoch 113/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.1872 - val_loss: 0.1292\n",
      "Epoch 114/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.1846 - val_loss: 0.1322\n",
      "Epoch 115/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1969 - val_loss: 0.1475\n",
      "Epoch 116/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1926 - val_loss: 0.1248\n",
      "Epoch 117/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.2023 - val_loss: 0.1961\n",
      "Epoch 118/200\n",
      "67/67 [==============================] - 17s 248ms/step - loss: 0.1906 - val_loss: 0.1374\n",
      "Epoch 119/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1990 - val_loss: 0.1665\n",
      "Epoch 120/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1922 - val_loss: 0.6336\n",
      "Epoch 121/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1956 - val_loss: 0.1441\n",
      "Epoch 122/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1888 - val_loss: 0.1365\n",
      "Epoch 123/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1858 - val_loss: 0.1391\n",
      "Epoch 124/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1884 - val_loss: 0.2961\n",
      "Epoch 125/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1915 - val_loss: 0.1835\n",
      "Epoch 126/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1867 - val_loss: 0.1564\n",
      "Epoch 127/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.2086 - val_loss: 0.1389\n",
      "Epoch 128/200\n",
      "67/67 [==============================] - 18s 268ms/step - loss: 0.1800 - val_loss: 0.1309\n",
      "Epoch 129/200\n",
      "67/67 [==============================] - 18s 269ms/step - loss: 0.1871 - val_loss: 0.1261\n",
      "Epoch 130/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1884 - val_loss: 0.1252\n",
      "Epoch 131/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1860 - val_loss: 0.1288\n",
      "Epoch 132/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1881 - val_loss: 0.1661\n",
      "Epoch 133/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1795 - val_loss: 0.1295\n",
      "Epoch 134/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1894 - val_loss: 0.1179\n",
      "Epoch 135/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1780 - val_loss: 0.1516\n",
      "Epoch 136/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1836 - val_loss: 0.2349\n",
      "Epoch 137/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.1860 - val_loss: 0.1210\n",
      "Epoch 138/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1793 - val_loss: 0.1333\n",
      "Epoch 139/200\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 0.1835 - val_loss: 0.1412\n",
      "Epoch 140/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1819 - val_loss: 0.1322\n",
      "Epoch 141/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1832 - val_loss: 0.1272\n",
      "Epoch 142/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1868 - val_loss: 0.1313\n",
      "Epoch 143/200\n",
      "67/67 [==============================] - 17s 251ms/step - loss: 0.1833 - val_loss: 0.1208\n",
      "Epoch 144/200\n",
      "67/67 [==============================] - 17s 248ms/step - loss: 0.1812 - val_loss: 0.1630\n",
      "Epoch 145/200\n",
      "67/67 [==============================] - 17s 248ms/step - loss: 0.1911 - val_loss: 0.1452\n",
      "Epoch 146/200\n",
      "67/67 [==============================] - 17s 252ms/step - loss: 0.1814 - val_loss: 0.1204\n",
      "Epoch 147/200\n",
      "67/67 [==============================] - 17s 249ms/step - loss: 0.1821 - val_loss: 0.1290\n",
      "Epoch 148/200\n",
      "67/67 [==============================] - 17s 250ms/step - loss: 0.1827 - val_loss: 0.1393\n",
      "Epoch 149/200\n",
      "67/67 [==============================] - 17s 249ms/step - loss: 0.1827 - val_loss: 0.1236\n",
      "Epoch 150/200\n",
      "67/67 [==============================] - 17s 253ms/step - loss: 0.1842 - val_loss: 0.1286\n",
      "Epoch 151/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1843 - val_loss: 0.1407\n",
      "Epoch 152/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1876 - val_loss: 0.1325\n",
      "Epoch 153/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1782 - val_loss: 0.1457\n",
      "Epoch 154/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1822 - val_loss: 0.1270\n",
      "Epoch 155/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1829 - val_loss: 0.1213\n",
      "Epoch 156/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1838 - val_loss: 0.1398\n",
      "Epoch 157/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1843 - val_loss: 0.1188\n",
      "Epoch 158/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1870 - val_loss: 0.1264\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1825 - val_loss: 0.1297\n",
      "Epoch 160/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1789 - val_loss: 0.1508\n",
      "Epoch 161/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1804 - val_loss: 0.1597\n",
      "Epoch 162/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1761 - val_loss: 0.1942\n",
      "Epoch 163/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1841 - val_loss: 0.1237\n",
      "Epoch 164/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1827 - val_loss: 0.1312\n",
      "Epoch 165/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1826 - val_loss: 0.1250\n",
      "Epoch 166/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1795 - val_loss: 0.1333\n",
      "Epoch 167/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1828 - val_loss: 0.1173\n",
      "Epoch 168/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1780 - val_loss: 0.1246\n",
      "Epoch 169/200\n",
      "67/67 [==============================] - 18s 262ms/step - loss: 0.1803 - val_loss: 0.1575\n",
      "Epoch 170/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1856 - val_loss: 0.1229\n",
      "Epoch 171/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1808 - val_loss: 0.1488\n",
      "Epoch 172/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1809 - val_loss: 0.1188\n",
      "Epoch 173/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1837 - val_loss: 0.1257\n",
      "Epoch 174/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1824 - val_loss: 0.1212\n",
      "Epoch 175/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1773 - val_loss: 0.1708\n",
      "Epoch 176/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1843 - val_loss: 0.1459\n",
      "Epoch 177/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1774 - val_loss: 0.1560\n",
      "Epoch 178/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1780 - val_loss: 0.1178\n",
      "Epoch 179/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1791 - val_loss: 0.1306\n",
      "Epoch 180/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1807 - val_loss: 0.1371\n",
      "Epoch 181/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1762 - val_loss: 0.1207\n",
      "Epoch 182/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1756 - val_loss: 0.1411\n",
      "Epoch 183/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1770 - val_loss: 0.1448\n",
      "Epoch 184/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1829 - val_loss: 0.1455\n",
      "Epoch 185/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1780 - val_loss: 0.1304\n",
      "Epoch 186/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1794 - val_loss: 0.1594\n",
      "Epoch 187/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1775 - val_loss: 0.1201\n",
      "Epoch 188/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1822 - val_loss: 0.1587\n",
      "Epoch 189/200\n",
      "67/67 [==============================] - 17s 260ms/step - loss: 0.1814 - val_loss: 0.1400\n",
      "Epoch 190/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.1797 - val_loss: 0.1195\n",
      "Epoch 191/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1742 - val_loss: 0.1194\n",
      "Epoch 192/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1778 - val_loss: 0.1172\n",
      "Epoch 193/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1850 - val_loss: 0.1224\n",
      "Epoch 194/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1773 - val_loss: 0.1211\n",
      "Epoch 195/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1750 - val_loss: 0.1152\n",
      "Epoch 196/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1794 - val_loss: 0.1261\n",
      "Epoch 197/200\n",
      "67/67 [==============================] - 17s 257ms/step - loss: 0.1794 - val_loss: 0.1165\n",
      "Epoch 198/200\n",
      "67/67 [==============================] - 17s 256ms/step - loss: 0.1803 - val_loss: 0.1168\n",
      "Epoch 199/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.1793 - val_loss: 0.2429\n",
      "Epoch 200/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.1798 - val_loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                              steps_per_epoch=67, \n",
    "                              epochs=200, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAJOCAYAAADGYfSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzde5hcVZ3u8fdHJyQ0CbdcFInpgAIBzJWASDAG0SO3Iwg4EHu4KlcdRzMi0ahk1PiMynMOhxFkIgNEjQZnUAYVb4AhKOORABEJJgiShgh4QpSQkATS3ev8sWpX77rvqt5Va1fn+3mefqpq165dq25d+63f2muZc04AAAAAgOzYLXQDAAAAAACFCGoAAAAAkDEENQAAAADIGIIaAAAAAGQMQQ0AAAAAMoagBgAAAAAZQ1ADgF2Ymf3EzM5Pe92QzGy9mb2rCdt1Zvbm3PkbzeyzSdZt4H66zeznjbazynbnmtmGtLcLAGiOYaEbAACoj5ltjV3slPSqpL7c5Uudc8uSbss5d1Iz1h3qnHOXpbEdM5sk6WlJw51zvbltL5OU+DUEAAxNBDUAaDPOuVHReTNbL+lDzrm7i9czs2HRzj8AAGgvdH0EgCEi6tpmZleZ2QuSbjGzfc3sR2a20cz+ljs/IXabFWb2odz5C8zsV2Z2TW7dp83spAbXPdDMVprZFjO728yuN7NvV2h3kjZ+wcx+ndvez81sbOz6c82sx8w2mdnCKs/PMWb2gpl1xJa9z8wezZ0/2sz+28xeMrPnzexrZrZ7hW3damZfjF2+Mneb58zsoqJ1TzGzR8zsZTN71swWxa5emTt9ycy2mtnbouc2dvtjzexBM9ucOz026XNTjZkdlrv9S2a2xszeG7vuZDN7PLfNP5vZJ3LLx+Zen5fM7K9mdr+ZsS8BAE3AP1cAGFpeL2k/SV2SLpH/P39L7vJESdslfa3K7d8qaZ2ksZK+IunfzcwaWPc7kn4raYykRZLOrXKfSdr4AUkXShovaXdJUXA4XNLXc9t/Q+7+JqgM59xvJL0i6Z1F2/1O7nyfpI/nHs/bJJ0g6Yoq7VauDSfm2vNuSQdLKj4+7hVJ50naR9Ipki43s9Nz183Jne7jnBvlnPvvom3vJ+nHkq7LPbb/JenHZjam6DGUPDc12jxc0g8l/Tx3u3+QtMzMDs2t8u/y3WhHS3qLpHtzy/9J0gZJ4yS9TtKnJbla9wcAqB9BDQCGln5JVzvnXnXObXfObXLO3e6c2+ac2yJpsaR3VLl9j3PuG865PklLJe0vv0OeeF0zmyjpKEmfc8695pz7laQ7K91hwjbe4px7wjm3XdL3JE3PLT9L0o+ccyudc69K+mzuOajku5LmSZKZjZZ0cm6ZnHMPOed+45zrdc6tl/RvZdpRzt/l2veYc+4V+WAaf3wrnHO/d871O+cezd1fku1KPtj90Tn3rVy7vitpraT/GVun0nNTzTGSRkn6l9xrdK+kHyn33EjaKelwM9vLOfc359zDseX7S+pyzu10zt3vnCOoAUATENQAYGjZ6JzbEV0ws04z+7dc18CX5bva7RPv/lfkheiMc25b7uyoOtd9g6S/xpZJ0rOVGpywjS/Ezm+LtekN8W3ngtKmSvclXz07w8xGSDpD0sPOuZ5cOw7Jdet7IdeOL8lX12opaIOknqLH91Yz+2Wua+dmSZcl3G607Z6iZT2SDohdrvTc1Gyzcy4eauPbPVM+xPaY2X1m9rbc8q9KelLSz83sT2a2INnDAADUi6AGAENLcXXjnyQdKumtzrm9NNDVrlJ3xjQ8L2k/M+uMLXtjlfUH08bn49vO3eeYSis75x6XDyQnqbDbo+S7UK6VdHCuHZ9upA3y3TfjviNfUXyjc25vSTfGtlurGvWcfJfQuImS/pygXbW2+8ai48vy23XOPeicO02+W+Qd8pU6Oee2OOf+yTl3kHxVb76ZnTDItgAAyiCoAcDQNlr+mK+Xcsc7Xd3sO8xVqFZJWmRmu+eqMf+zyk0G08b/lHSqmR2XG/jj86r93fYdSR+VD4T/UdSOlyVtNbPJki5P2IbvSbrAzA7PBcXi9o+WrzDuMLOj5QNiZKN8V82DKmz7LkmHmNkHzGyYmZ0t6XD5boqD8X/lj537pJkNN7O58q/R8txr1m1mezvndso/J32SZGanmtmbc8ciRsv7yt8FAGAwCGoAMLRdK2kPSS9K+o2kn7bofrvlB+TYJOmLkm6Tn++tnIbb6JxbI+nD8uHreUl/kx/soprvSpor6V7n3Iux5Z+QD1FbJH0j1+YkbfhJ7jHcK98t8N6iVa6Q9Hkz2yLpc8pVp3K33SZ/TN6vcyMpHlO07U2STpWvOm6S9ElJpxa1u27OudckvVe+sviipBskneecW5tb5VxJ63NdQC+T9Pe55QdLulvSVkn/LekG59yKwbQFAFCecQwwAKDZzOw2SWudc02v6AEAMBRQUQMApM7MjjKzN5nZbrnh60+TP9YJAAAkMCx0AwAAQ9LrJX1ffmCPDZIud849ErZJAAC0D7o+AgAAAEDG0PURAAAAADImWNfHsWPHukmTJoW6ewAAAAAI6qGHHnrROTeu3HXBgtqkSZO0atWqUHcPAAAAAEGZWU+l6+j6CAAAAAAZQ1ADAAAAgIwhqAEAAABAxjCPGgAAANCGdu7cqQ0bNmjHjh2hm4IaRo4cqQkTJmj48OGJb0NQAwAAANrQhg0bNHr0aE2aNElmFro5qMA5p02bNmnDhg068MADE9+Oro8AAABAG9qxY4fGjBlDSMs4M9OYMWPqrnwS1AAAAIA2RUhrD428TgQ1AAAAAMgYghoAAACAum3atEnTp0/X9OnT9frXv14HHHBA/vJrr71W9barVq3SRz/60Zr3ceyxx6bS1hUrVujUU09NZVutwmAiAAAAwC5g2TJp4ULpmWekiROlxYul7u7GtzdmzBitXr1akrRo0SKNGjVKn/jEJ/LX9/b2atiw8nFj1qxZmjVrVs37eOCBBxpvYJujogYAAAAMccuWSZdcIvX0SM7500su8cvTdMEFF2j+/Pk6/vjjddVVV+m3v/2tjj32WM2YMUPHHnus1q1bJ6mwwrVo0SJddNFFmjt3rg466CBdd911+e2NGjUqv/7cuXN11llnafLkyeru7pZzTpJ01113afLkyTruuOP00Y9+tGbl7K9//atOP/10TZ06Vcccc4weffRRSdJ9992XrwjOmDFDW7Zs0fPPP685c+Zo+vTpestb3qL7778/3SesCipqAAAAwBC3cKG0bVvhsm3b/PLBVNXKeeKJJ3T33Xero6NDL7/8slauXKlhw4bp7rvv1qc//WndfvvtJbdZu3atfvnLX2rLli069NBDdfnll5fMOfbII49ozZo1esMb3qDZs2fr17/+tWbNmqVLL71UK1eu1IEHHqh58+bVbN/VV1+tGTNm6I477tC9996r8847T6tXr9Y111yj66+/XrNnz9bWrVs1cuRILVmyRO95z3u0cOFC9fX1aVvxk9hEBDUAAABgiHvmmfqWD8b73/9+dXR0SJI2b96s888/X3/84x9lZtq5c2fZ25xyyikaMWKERowYofHjx+svf/mLJkyYULDO0UcfnV82ffp0rV+/XqNGjdJBBx2Un59s3rx5WrJkSdX2/epXv8qHxXe+853atGmTNm/erNmzZ2v+/Pnq7u7WGWecoQkTJuioo47SRRddpJ07d+r000/X9OnTB/Xc1IOujwAAAMAQN3FifcsHY88998yf/+xnP6vjjz9ejz32mH74wx9WnEtsxIgR+fMdHR3q7e1NtE7U/bEe5W5jZlqwYIFuuukmbd++Xcccc4zWrl2rOXPmaOXKlTrggAN07rnn6pvf/Gbd99coghoAAAAwxC1eLHV2Fi7r7PTLm2nz5s064IADJEm33npr6tufPHmy/vSnP2n9+vWSpNtuu63mbebMmaNluYPzVqxYobFjx2qvvfbSU089pSlTpuiqq67SrFmztHbtWvX09Gj8+PG6+OKL9cEPflAPP/xw6o+hEoIaAAAAMMR1d0tLlkhdXZKZP12yJP3j04p98pOf1Kc+9SnNnj1bfX19qW9/jz320A033KATTzxRxx13nF73utdp7733rnqbRYsWadWqVZo6daoWLFigpUuXSpKuvfZaveUtb9G0adO0xx576KSTTtKKFSvyg4vcfvvt+sd//MfUH0Ml1ki5MA2zZs1yq1atCnLfAAAAQLv7wx/+oMMOOyx0M4LbunWrRo0aJeecPvzhD+vggw/Wxz/+8dDNKlHu9TKzh5xzZecpoKIGAAAAoG194xvf0PTp03XEEUdo8+bNuvTSS0M3KRWM+ggAAACgbX384x/PZAVtsKioAQAAAEDGENQAAAAAIGMIagAAAACQMQQ1AABQor/fD9v9wAOhWwIAuyaCGgAAKLF9u/Sd70grV4ZuCYCsmjt3rn72s58VLLv22mt1xRVXVL1NNEXXySefrJdeeqlknUWLFumaa66pet933HGHHn/88fzlz33uc7r77rvraX5ZK1as0Kmnnjro7aSBoAYAAEr09xeeAkCxefPmafny5QXLli9frnnz5iW6/V133aV99tmnofsuDmqf//zn9a53vauhbWUVQQ0AAJQgqAGo5ayzztKPfvQjvfrqq5Kk9evX67nnntNxxx2nyy+/XLNmzdIRRxyhq6++uuztJ02apBdffFGStHjxYh166KF617vepXXr1uXX+cY3vqGjjjpK06ZN05lnnqlt27bpgQce0J133qkrr7xS06dP11NPPaULLrhA//mf/ylJuueeezRjxgxNmTJFF110Ub59kyZN0tVXX62ZM2dqypQpWrt2bdXH99e//lWnn366pk6dqmOOOUaPPvqoJOm+++7T9OnTNX36dM2YMUNbtmzR888/rzlz5mj69Ol6y1veovvvv39wT66YRw0AAJTR1+dPCWpAe/jYx6TVq9Pd5vTp0rXXVr5+zJgxOvroo/XTn/5Up512mpYvX66zzz5bZqbFixdrv/32U19fn0444QQ9+uijmjp1atntPPTQQ1q+fLkeeeQR9fb2aubMmTryyCMlSWeccYYuvvhiSdJnPvMZ/fu//7v+4R/+Qe9973t16qmn6qyzzirY1o4dO3TBBRfonnvu0SGHHKLzzjtPX//61/Wxj31MkjR27Fg9/PDDuuGGG3TNNdfopptuqvj4rr76as2YMUN33HGH7r33Xp133nlavXq1rrnmGl1//fWaPXu2tm7dqpEjR2rJkiV6z3veo4ULF6qvr0/btm2r56kui4oaAAAoQUUNQBLx7o/xbo/f+973NHPmTM2YMUNr1qwp6KZY7P7779f73vc+dXZ2aq+99tJ73/ve/HWPPfaY3v72t2vKlClatmyZ1qxZU7U969at04EHHqhDDjlEknT++edrZexg2zPOOEOSdOSRR2r9+vVVt/WrX/1K5557riTpne98pzZt2qTNmzdr9uzZmj9/vq677jq99NJLGjZsmI466ijdcsstWrRokX7/+99r9OjRVbedBBU1AABQgqAGtJdqla9mOv300zV//nw9/PDD2r59u2bOnKmnn35a11xzjR588EHtu+++uuCCC7Rjx46q2zGzsssvuOAC3XHHHZo2bZpuvfVWrVixoup2nHNVrx8xYoQkqaOjQ729vXVvy8y0YMECnXLKKbrrrrt0zDHH6O6779acOXO0cuVK/fjHP9a5556rK6+8Uuedd17V7ddCRQ0AAJQgqAFIYtSoUZo7d64uuuiifDXt5Zdf1p577qm9995bf/nLX/STn/yk6jbmzJmjH/zgB9q+fbu2bNmiH/7wh/nrtmzZov333187d+7UsmXL8stHjx6tLVu2lGxr8uTJWr9+vZ588klJ0re+9S294x3vaOixzZkzJ3+fK1as0NixY7XXXnvpqaee0pQpU3TVVVdp1qxZWrt2rXp6ejR+/HhdfPHF+uAHP6iHH364ofuMo6IGAABKRAEtOlYNACqZN2+ezjjjjHwXyGnTpmnGjBk64ogjdNBBB2n27NlVbz9z5kydffbZmj59urq6uvT2t789f90XvvAFvfWtb1VXV5emTJmSD2fnnHOOLr74Yl133XX5QUQkaeTIkbrlllv0/ve/X729vTrqqKN02WWXNfS4Fi1apAsvvFBTp05VZ2enli5dKslPQfDLX/5SHR0dOvzww3XSSSdp+fLl+upXv6rhw4dr1KhR+uY3v9nQfcZZrfJgs8yaNctFcygAAIBsefZZaeJE6ZOflL785dCtAVDOH/7wBx122GGhm4GEyr1eZvaQc25WufXp+ggAAErQ9REAwiKoAQCAEgQ1AAiLoAYAAEoQ1ID2EOowJtSnkdeJoAYAAEoQ1IDsGzlypDZt2kRYyzjnnDZt2qSRI0fWdTtGfQQAACWi0R4JakB2TZgwQRs2bNDGjRtDNwU1jBw5UhMmTKjrNgQ1AABQgooakH3Dhw/XgQceGLoZaBK6PgIAgBIENQAIi6AGAABKMOE1AIRFUAMAACWoqAFAWAQ1AABQgsFEACAsghoAAChBRQ0AwiKoAQCAEgQ1AAiLoAYAAEoQ1AAgLIIaAAAoQVADgLAIagAAoASDiQBAWAQ1AABQgooaAIRFUAMAACWY8BoAwiKoAQCAElTUACAsghoAACjBMWoAEBZBDQAAlKCiBgBhJQpqZnaima0zsyfNbEGFdeaa2WozW2Nm96XbTAAA0EoENQAIa1itFcysQ9L1kt4taYOkB83sTufc47F19pF0g6QTnXPPmNn4ZjUYAAA0H0ENAMJKUlE7WtKTzrk/Oedek7Rc0mlF63xA0vedc89IknPu/6XbTAAA0EoENQAIK0lQO0DSs7HLG3LL4g6RtK+ZrTCzh8zsvHIbMrNLzGyVma3auHFjYy0GAABNx2AiABBWkqBmZZa5osvDJB0p6RRJ75H0WTM7pORGzi1xzs1yzs0aN25c3Y0FAACtQUUNAMKqeYyafAXtjbHLEyQ9V2adF51zr0h6xcxWSpom6YlUWgkAAFqKCa8BIKwkFbUHJR1sZgea2e6SzpF0Z9E6/yXp7WY2zMw6Jb1V0h/SbSoAAGgVKmoAEFbNippzrtfMPiLpZ5I6JN3snFtjZpflrr/ROfcHM/uppEcl9Uu6yTn3WDMbDgAAmoegBgBhJen6KOfcXZLuKlp2Y9Hlr0r6anpNAwAAoTCYCACElWjCawAAsGuhogYAYRHUAABACYIaAIRFUAMAACUIagAQFkENAACUIKgBQFgENQAAUILBRAAgLIIaAAAowYTXABAWQQ0AAJSg6yMAhEVQAwAAJQhqABAWQQ0AAJQgqAFAWAQ1AABQgsFEACAsghoAAChBRQ0AwiKoAQCAEgQ1AAiLoAYAAEoQ1AAgLIIaAAAowTFqABAWQQ0AAJRgwmsACIugBgAAStD1EQDCIqgBAIASBDUACIugBgAAShDUACAsghoAACjBYCIAEBZBDQAAlKCiBgBhEdQAAEAJghoAhEVQAwAAJQhqABAWQQ0AAJQgqAFAWAQ1AABQgsFEACAsghoAACgRBbQosAEAWougBgAAStD1EQDCIqgBAIASBDUACIugBgAASsQDmnPh2gEAuyqCGgAAKBE/No2qGgC0HkENAACUiIczghoAtB5BDQAAlCCoAUBYBDUAAFCCoAYAYRHUAABACYIaAIRFUAMAACXig4kw6TUAtB5BDQAAlKCiBgBhEdQAAEAJghoAhEVQAwAAJQhqABAWQQ0AAJRgwmsACIugBgAASlBRA4CwCGoAAKAEQQ0AwiKoAQCAEgQ1AAiLoAYAAEoQ1AAgLIIaAAAowYTXABAWQQ0AAJSgogYAYRHUAABACYIaAIRFUAMAACUIagAQFkENAACUIKgBQFgENQAAUCI+gAhBDQBaj6AGAABKUFEDgLAIagAAoARBDQDCIqgBAIASBDUACIugBgAASvT3S7vl9hKY8BoAWo+gBgAASvT1ScOG+fNU1ACg9QhqAACgRH8/QQ0AQiKoAQCAEgQ1AAiLoAYAAEr090vDhw+cBwC0FkENAACUoKIGAGER1AAAQAkGEwGAsAhqAACgBF0fASAsghoAAChB10cACIugBgAASsQrakx4DQCtR1ADAAAlqKgBQFgENQAAUILBRAAgLIIaAAAoQUUNAMIiqAEAgBKM+ggAYRHUAABACSpqABAWQQ0AAJTgGDUACIugBgAAStD1EQDCIqgBAIASdH0EgLAIagAAoAQTXgNAWAQ1AABQgooaAIRFUAMAACUYTAQAwiKoAQCAElTUACAsghoAACjgnP8jqAFAOAQ1AABQwDl/yvD8ABAOQQ0AABSIghkVNQAIh6AGAAAKRMPxE9QAIByCGgAAKBAFM7o+AkA4BDUAAFCguOsjE14DQOsR1AAAQAEqagAQHkENAAAUYDARAAiPoAYAAAowmAgAhEdQAwAABaioAUB4BDUAAFCAoAYA4RHUAABAAQYTAYDwCGoAAKAAFTUACC9RUDOzE81snZk9aWYLylw/18w2m9nq3N/n0m8qAABohWgwESpqABDOsFormFmHpOslvVvSBkkPmtmdzrnHi1a93zl3ahPaCAAAWoiKGgCEl6SidrSkJ51zf3LOvSZpuaTTmtssAAAQShTMOjoks4EKGwCgdZIEtQMkPRu7vCG3rNjbzOx3ZvYTMzui3IbM7BIzW2VmqzZu3NhAcwEAQLNFQW233fwfFTUAaL0kQc3KLHNFlx+W1OWcmybpXyXdUW5DzrklzrlZzrlZ48aNq6+lAACgJaIKGkENAMJJEtQ2SHpj7PIESc/FV3DOveyc25o7f5ek4WY2NrVWAgCAlqGiBgDhJQlqD0o62MwONLPdJZ0j6c74Cmb2ejOz3Pmjc9vdlHZjAQBA8xHUACC8mqM+Oud6zewjkn4mqUPSzc65NWZ2We76GyWdJelyM+uVtF3SOc654u6RAACgDcQHEyGoAUAYNYOalO/OeFfRshtj578m6WvpNg0AAIRARQ0Awks04TUAANh1xAcT6eggqAFACAQ1AABQgIoaAIRHUAMAAAWKgxoTXgNA6xHUAABAAQYTAYDwCGoAAKAAXR8BIDyCGgAAKBAfTISgBgBhENQAAEABKmoAEB5BDQAAFCCoAUB4BDUAAFCAwUQAIDyCGgAAKBCvqDHhNQCEQVADAAAFGEwEAMIjqAEAgAJMeA0A4RHUAABAAY5RA4DwCGoAAKAAoz4CQHgENQAAUICgBgDhEdQAAEABBhMBgPAIagAAoAAVNQAIj6AGAAAKMJgIAIRHUAMAAAWoqAFAeAQ1AABQIH6MWkcHQQ0AQiCoAQCAAkx4DQDhEdQAAEABuj4CQHgENQAAUIDBRAAgPIIaAAAoQEUNAMIjqAEAgAJMeA0A4RHUAABAASpqABAeQQ0AABQgqAFAeAQ1AABQgMFEACA8ghoAACgQr6gx4TUAhEFQAwAABYoHE2HCawBoPYIaAAAowDFqABAeQQ0AABQgqAFAeAQ1AABQgMFEACA8ghoAAChARQ0AwiOoAQCAAsWDiRDUAKD1CGoAAKAAFTUACI+gBgAAChDUACA8ghoAACjQ3y+Z+T8mvAaAMAhqAACgQH+/r6RJTHgNAKEQ1AAAQIG+vsKgRkUNAFqPoAYAAAoUV9QIagDQegQ1AABQoL/fH5smEdQAIBSCGgAAKEBFDQDCI6gBAIACBDUACI+gBgAACjCYCACER1ADAAAFqKgBQHgENQAAUIDBRAAgPIIaAAAoEK+odXQw4TUAhEBQAwAABThGDQDCI6gBAIACHKMGAOER1AAAQAGCGgCER1ADAAAFGEwEAMIjqAEAgAJU1AAgPIIaAAAoUDyYiHP+DwDQOgQ1AABQoLiiJhHUAKDVCGoAAKBAuaBG90cAaC2CGgAAKBAfTCQ6JagBQGsR1AAAQIFyFbW+vnDtAYBdEUENAAAUKB5MRKKiBgCtRlADAAAFOEYNAMIjqAEAgALFE15HywAArUNQAwAABaioAUB4BDUAAFCAoAYA4RHUAABAAQYTAYDwCGoAAKAAFTUACI+gBgAACjDhNQCER1ADAAAFmPAaAMIjqAEAgAJ0fQSA8AhqAACgAIOJAEB4BDUAAFCAihoAhEdQAwAABeKDiRDUACAMghoAAChARQ0AwiOoAQCAAhyjBgDhEdQAAEABKmoAEB5BDQAAFCCoAUB4BDUAAFAgPphIdMqE1wDQWgQ1AABQgIoaAIRHUAMAAAUYTAQAwiOoAQCAAlTUACA8ghoAAChAUAOA8AhqAACgQHwwEYIaAIRBUAMAAAWoqAFAeAQ1AABQgMFEACA8ghoAAChARQ0AwiOoAQCAAkx4DQDhEdQAAEABKmoAEB5BDQAAFCCoAUB4iYKamZ1oZuvM7EkzW1BlvaPMrM/MzkqviQAAoJUYTAQAwqsZ1MysQ9L1kk6SdLikeWZ2eIX1vizpZ2k3EgAAtA4VNQAIL0lF7WhJTzrn/uSce03SckmnlVnvHyTdLun/pdg+AADQYkx4DQDhJQlqB0h6NnZ5Q25ZnpkdIOl9km6stiEzu8TMVpnZqo0bN9bbVgAA0AJU1AAgvCRBzcosc0WXr5V0lXOu6uC9zrklzrlZzrlZ48aNS9pGAADQQgQ1AAhvWIJ1Nkh6Y+zyBEnPFa0zS9JyM5OksZJONrNe59wdqbQSAAC0DIOJAEB4SYLag5IONrMDJf1Z0jmSPhBfwTl3YHTezG6V9CNCGgAA7SleUWPCawAIo2ZQc871mtlH5Edz7JB0s3NujZldlru+6nFpAACgfTjn/xhMBADCSlJRk3PuLkl3FS0rG9CccxcMvlkAACAElzsKna6PABBWogmvAQDAriHq4khQA4CwCGoAACAvCmQENQAIi6AGAADyCGoAkA0ENQAAkBcFMgYTAYCwCGoAACCPihoAZANBDQAA5DGYCABkA0ENAADkVaqoMeE1ALQWQQ0AAOQVB7XoWDUqagDQWgQ1AACQx2AiAJANBDUAAJDHYCIAkA0ENQAAkMdgIgCQDQQ1AACQR0UNALKBoAYAAPI4Rg0AsoGgBgAA8qioAUA2ENQAAEAeQQ0AslKuc+gAACAASURBVIGgBgAA8ioNJsKE1wDQWgQ1AACQx4TXAJANBDUAAJDHYCIAkA0ENQAAkFdcUTMrXA4AaA2CGgAAyCsOatF5ghoAtBZBDQAA5BUPJhKdJ6gBQGsR1AAAQB4VNQDIBoIaAADIKx5MRCKoAUAIBDUAAJBHRQ0AsoGgBgAA8ioFNSa8BoDWIqgBAIC8coOJdHRQUQOAViOoAQCAPLo+AkA2ENQAAEAeg4kAQDYQ1AAAQB4VNQDIBoIaAADIY8JrAMgGghoAAMijogYA2UBQAwAAeQQ1AMgGghoAAMhjMBEAyAaCGgAAyKOiBgDZQFADAAB5lQYTiZYDAFqDoAYAAPLKVdQ6OqioAUCrEdQAAEAex6gBQDYQ1AAAQB7HqAFANhDUAABAHkENALKBoAYAAPIqDSZCUAOA1iKoAQCAPCpqAJANBDUAAJDHYCIAkA0ENQAAkEdFDQCygaAGAADyKgU1JrwGgNYiqAEAgLxyg4kw4TUAtB5BDQAA5NH1EQCygaAGAADyGEwEALKBoAYAAPKoqAFANhDUAABAHkENALKBoAYAAPLKDSZCUAOA1iOoAQCAPCpqAJANBDUAAJDHYCIAkA0ENQAAkMeE1wCQDQQ1AACQx4TXAJANBDUAAJDHMWoAkA0ENQAAkEdQA4BsIKgBAIA8ghoAZANBDQAA5PX3S2b+L0JQA4DWI6gBAIC8vr7CappEUAOAEAhqAAAgr7+foAYAWUBQAwAAef39hZNdSwQ1AAiBoAYAAPIqVdSY8BoAWougBgAA8soFNSa8BoDWI6gBAIA8BhMBgGwgqAEAgDwGEwGAbCCoAQCAPAYTAYBsIKgBAIA8KmoAkA0ENQAAkEdQA4BsIKgBAIA8BhMBgGwgqAEAgDwqagCQDQQ1AACQV2kwESa8BoDWIqgBAIA8KmoAkA0ENQAAkFcuqHV0ENQAoNUIagAAII/BRAAgGwhqAAAgj66PAJANBDUAAJBXaTARghoAtBZBDQAA5FFRA4BsIKgBAIA8jlEDgGwgqAEAgDwqagCQDQQ1AACQVymoRdcBAFqDoAYAAPIqDSYSXQcAaA2CGgAAyKs04XV0HQCgNQhqAAAgr9JgIhJBDQBaiaAGAADyOEYNALKBoAYAAPI4Rg0AsoGgBgAA8qioAUA2JApqZnaima0zsyfNbEGZ608zs0fNbLWZrTKz49JvKgAAaDaCGgBkw7BaK5hZh6TrJb1b0gZJD5rZnc65x2Or3SPpTuecM7Opkr4naXIzGgwAAJqnr0/afffCZQQ1AGi9JBW1oyU96Zz7k3PuNUnLJZ0WX8E5t9U553IX95TkBAAA2k61ilpfX+vbAwC7qiRB7QBJz8Yub8gtK2Bm7zOztZJ+LOmichsys0tyXSNXbdy4sZH2AgCAJmIwEQDIhiRBzcosK6mYOed+4JybLOl0SV8otyHn3BLn3Czn3Kxx48bV11IAANB0THgNANmQJKhtkPTG2OUJkp6rtLJzbqWkN5nZ2EG2DQAAtBiDiQBANiQJag9KOtjMDjSz3SWdI+nO+Apm9mYzs9z5mZJ2l7Qp7cYCAIDm6utLJ6h96lPSqaem1y4A2NXUDGrOuV5JH5H0M0l/kPQ959waM7vMzC7LrXampMfMbLX8CJFnxwYXaQvLlkmTJvkvo0mT/GUAAHY1aVXU1q6V1qxJr10AsKupOTy/JDnn7pJ0V9GyG2Pnvyzpy+k2rXWWLZMuuUTats1f7unxlyWpuztcuwAAaLW0BhN59VVp+/b02gUAu5pEE14PdQsXDoS0yLZt0vnnU2EDAOxa0qqovfYaQQ0ABiNRRW2oe+aZ8suj+WKosAEAdhVpBTUqagAwOFTUJE2cWHudbdt85Q0AgKEsrcFEXn1V2rlT6u1Nr20AsCshqElavFjq7Ky9XqXKGwAAQ0W1ilrU0ySJ117zp1TVAKAxBDX57oxLlkhdXZJZ6UHUkSSVNwAA2lmag4lIBDUAaBRBLae7W1q/3n8JLV1aWmHr7PSVNwAAhrJyFbUouNU7mIhEUAOARhHUyiiusHV1+csMJAIAGOrSHExEIqgBQKMY9bGC7m6CGQBg15PWYCJU1ABgcKioAQCAPCpqAJANBDUAAJDHYCIAkA0ENQAAkJdGRc25ga6P27al1zYA2JUQ1AAAQF4ax6j19vqwJlFRA4BGEdQAAEBeGhNeR9U0iaAGAI0iqAEAgLw0jlGLjk+TCGoA0CiCGgAAyEtjwmsqagAweAQ1AACQl8ZgIlTUAGDwCGoAACAvjcFE4kGNUR8BoDEENQAAkJdGRY2ujwAweAQ1AACQx2AiAJANBDUAACDJz33mHBU1AMgCghoAAJA0MEk1g4kAQHgEtYSWLZMmTfJfVpMm+csAAAwl0YTWTHgNAOENC92AdrBsmXTJJQMjV/X0+MuS1N0drl0AAKQpqpilVVEbPpxRHwGgUVTUEli4sPSLZts2vxwAgKEiCmLFg4nUO+F1FNT22YeKGgA0iqCWwDPP1LccAIB2lFZFLer6SFADgMYR1BKYOLG+5QBQy9at0tSp0m9/G7olwIC0uz7uvTdBDQAaRVBLYPFiqbOzcFlnp18OAI147jnp97+XHnkkdEuAAbUGE6GiBgCtQ1BLoLtbWrJE6uqSzPzpkiUMJAKgcTt2+FMGWkCWpF1RI6gBQOMY9TGh7m6CGYD0REGNnVhkSaXBRAZTUePHCABoDBU1AAiAihqyiGPUACA7CGoAEAAVNWRRraCWdMLrKKjttZfU2+v/AAD1IailZNkyadIk/2U2aZK/DACVUFFDFqU5mMiIEdIee/jL/CABAPXjGLUULFsmXXLJwA5XT4+/LHFcG4DyCGrIojS7Po4YMTBi8vbt0ujR6bQRAHYVVNRSsHBh6c7Wtm1+OQCUQ9dHZFGlwUSiy/VU1HbfnYoaAAwGQa1B8a6OPT3l13nmmZY2CUAboaKGLEq7ohYFNd7nAFA/uj42oLirYyUTJ7amPQDaD0ENWZTmMWpU1ABgcKioNaBcV8dinZ3S4sWtaQ+A9kPXR2RRsypqvM8BoH4EtQZU69JoJnV1SUuWMJAIgMqoqCGL0prw+tVXfUUtPpgIAKA+dH1swMSJ5Y9L6+qS1q9veXMAtCGCGrIorYoaw/MDwOBRUWvA4sUDvxJG4l0dmVMNQC10fUQWpTnhNUENAAaHoNaA7m7ftbGrq7SrYzTQSE+P5NzAnGqENQBxVNSQRc0aTIT3OQDUj6DWoO5u382xv9+fRsejMacagCSoqCGLGEwEALKDoJaySgONMKcagLgoqO3YkXznF2g2JrwGgOwgqKWs0txpzKkGIC4KahI7sciOtCtqjPoIAI0jqKWs1kAjACAR1JBNlYKaWeH1tUTD8w8f7rfFexwA6kdQS1m1gUaSYtRIYOiLBzUGWkBWVBpMxMz/1Ts8v5nv/khQA4D6MY9aE3R3Nz7ZdTRqZLTjFo0aGW0XwNBAUEMWVaqoRcvq7foo+aDGexwA6kdFLYBqFTNGjQR2DXR9RBZVGkxEqi+oRYOJSFTUALTeli3SihWhWzF4BLUWKzfP2oUXSmPH+i/Bnp7yt2PUSGBo2bFD2ntvf55qA7KiVkWt3gmvJYIagNb75jelE06QXn45dEsGh6DWAvEK2vnnl+6U7dwpbdrkg1sljBoJDC2vvirtu68/z04ssiKNro/OFVbUOjt5jwNorc2b/f+rrVtDt2RwCGpNVlxBS/prZByjRgJDz44dA0GNihqyotJgItGyJEGtt9d/31FRAxBK9D8nfphBOyKoNVm5Y86SanTUSADZt2OHtN9+/jxBDVlRraLW0ZEsqL36qj/lGDUAoUQBrd2DGqM+xvz+99KDD0oXXZTeNhs9tqyrS1q/Pr12AMiWeEWNnVhkRRqDibz2mj+NV9Reeimd9gFAElFAa/fvVypqMd//vvShD0mvvJLeNisdW9bR4StmY8YM/OoYoasjMLQ5R0UN2ZTGMWpRRY3h+QGEMlQqagS1mBkz/A7U736X3jYXL/bBK66zU1q61H/hvfiidPPNg5sgG0B76e31n3+CGrImjaAWVdTo+gggFILaEDRzpj995JH0ttnd7YNXtSDW3e27Ofb3+1NCGjC0RV8cdH1E1qQxmEhxRa3dRn38xS+k+fNDtwLAYBDUhqADDvDzmT38cLrbJYgBiIu+OPbc01cdqKghK6ioSf/1X9L114duBYDBiP7ntNP/nnIIajFmvqqWZkWtGeLzsk2a5C8DaB9RUBs50lcbCGrIilqDiSSZYqbcMWrttLO0dasPm41MpwMgG6ioDVEzZ0qPPTbwRZM1xfOy9fT4y4Q1oH3Eg1q77cRiaEtzMJF4Ra23V9q5M502NtuWLf603XfwgF0ZQW2ImjHDf5msWRO6JQPiFbTzzy/99X3bNunv/57qGtAuqKghq9I4Rq3c8PxS+/wgsXWrP22X9gIoxfD8Q1QzBhQZjOIKWrWuGFTXgPZQHNTa/YsEQ0czhuePRj5ul/c5QQ1of1TUhqiDDpJGj05/QJFGLVxY36/t27b52wDIruKuj1TUkBXVjlHr6Gh8MBGpfYJP1PWxXdoLoBRBbYjabTff/TErFbVnnmnNbQC0Dl0fkVXNmvBaap/gE1XU+FwC7YtRH4ewGTP8pNdZGPFp4sTyy8v92lnrNgCyga6PyKpmDc8vtc/7nIoa0P6oqA1hM2f6X9KeeCJ0S6TFiwf690c6O6WlS6Vvf7v8dYsXD1xmKH8ge+j6iKxqxoTX7RbUOEYNaH8EtSFsxgx/moXj1Lq7pSVLpK4uP89bV5e/3N1d/TqpsaH8CXZA89H1EVnVrOH5pfZ4n/f2Dp3R4oBdlXND53NMUCvjsMP8DlRWjlPr7pbWr/dfkOvXDwSxWteVG4ik2mAjzNEGtAbzqCGrak143cjw/O006mNUTZPao70ASvX2DvyvoqI2BA0bJk2Zko2K2mBUGlSkp6d8xazeYAegMVTUkFW1KmpJjt1u566PBDWg/cU/uwS1IWrmTF9Rcy50SxpXbVCRchWzSsGOUSSBdBHUkFW7+mAiBDWg/cXDWbt/jglqFcyYIb30ku9O2K7KDURSbNs26fzz/RdwuS9myYe6Ro5X43g3oLzoS2TECL8T29cn7dwZtk2AlN5gIma+d4rUXkEtGvFRao/2AigVD2pU1IaomTP9aVaOU0sqHo4WLvQhLBpspJK+Ph/GqnVpKXe8WrUgxvFuQGU7dvid2GHDBn5MoaqGLKhWUatnwuvddx/43mmnoEZFDWh/BLVdwJQp/kupnY5TKxeOli71lbX+fh/Ykqg0R1v8eLVaQayRgUyovmFXsWOH7/YotddACxj60hhM5NVXB45Pk9pr1EcqakD7o+vjLmDkSOnww9urolYrHCXpCin5L+JKFbjoeLVa91XreLd4MBs7VrroIqpv2HXEg1o77cRi6EtreP7o+DRJGj7cB7922GGioga0vyio7bUXFbUhbcaM9gpqtcJR8bxrlSpnEydWHogkWl7rvqrdvrgat2nTwMHnEUabxFAWrzjQ9RFZktZgIvGKmln7TENBUAPaX/TZ3WcfgtqQNm2a9Pzz0osvhm5JMrXClVQ479rSpaUVts5OX3krV30bPtx/iVUbeCS6r3K3j7ZdrhpXTrXRJtPsKkm3S7QaXR+RVWkNJhIPalL7BLWo6+OoUe3RXgClonC2zz7t/zkmqFUxdao/ffTRsO1Iqlo4Kqe4wtbV5S93d5deN2aMP920qfLAI/H7Krft88/3Ia2nJ9njqRQ8kwxUUhy+li6VHnqosW0BaaPrI7IqrYpavOuj1D5BLaqojRvXHu0FUCoKavvuS0VtSIuC2u9+F7YdSVULXtVuE1XY1q8vXDd+3ahRpd0TJd99stJ9xW+/eLEPS0lDWrWAWev4uHLh64ILpFmzpAkTmOQb4ZWrqBHUkAW1BhNJOuF1u1bUtm71baWiBrSveEWNoDaEjR8vvf717VNRk6oHr8Go1A2xvz/ZfdXq7jh8+EDVLl59K9cdsdbxcdXu689/bu4k33SjRBJ0fURWRUGt3IBSg6motcvE7lu2+JDWLsESQKl4RW3nzmQ/MGUVQa2GqVPbK6g1S5Lj36qpFny6uqRbbvHHAhZX38p1R2x0oJNIkkm+o+vqCVt0o0RSdH1EVkWj/g4mqDVSUcvKj1xbt0qjR/v28pkE2lP0v2bfff1pO1fVCGo1TJsmrVkj9faGbklY9R7/VqxSuOrqKq3GVeqOGIWrrVvL/1obtSVJeKw1yXd0fT1hq5FulFnZOUFr0fURWdXXV/kHrKQTXhcPzy9VD2pZ+pFr61YqakC7i3d9jF9uRwS1GqZO9V86TzwRuiVhJTn+rVroqCfoVaqIReEpGtAk3lUy3pak88XFRcfalTsuIx4Sq4WpertRZmnnBK1VrqLGTiGyoL+/ek+DRobnl6oHnywdK0zXR6D9EdR2Ie02oEgzVTv+rVboqGegkyQVsZ07/Zdp1BZpICQuXOiDVVeXX15p8u646Fi7SjshSSpsSbqHxsPs+edXrxxSYatfu1Qoqaghq/r7K8+x2ayuj2kfKzwY8a6PBDWgPRUHtXb+LBPUapg82Q90wXFq1SX5RTTpQCdJK2LRl3i5kLh0qd+Oc9K3vjWwU1xJFKaShMRKv/TWqhoWtzNJt8tzz/VBs5HQ0S6hJS3tVKGMB7URI/xr3M5fJBg60qqo1dP1cbDHQKeJihrQ/nbs8N+tUY8VKmpD2O67S4cdRlCrJc1fRIurb5V+3Y2+xGuFxO7ugcroG95QPUzVGxKrtbu4aph0ou845/xpvaGjkbnmshho6pGl7lO1xIOaGQMXIDvSCGrlKmrVRn0c7DHQaeIYNaD97djhP8PR9yxBbYibNo2uj7Wk/YtovPq2dGn1L/EkIfHll/3pK69UD1NJQ2KlUSGLq4bSQBhKOodcJcXdIq+4ojBoxS9X6lZZba65rFafkmrkx4JQYTUe1KT2Gboc7S3J+73aYCLNqqg1Mgdos9D1EWh/27f779ihcAw4QS2BqVP9/FubNoVuSXY18xfRWl/iSULi5s0Dp+97X/UumLVCopSse2JxGKqk2kAm1e73618vDFrxy5W6VVaba24w1adqO4CtCkP1/lgQMqyWC2rt/EWC7Ev6fq91jFqzJrxu1hyg9XCusOvjjh3V/3cDyKboO3aXqaiZ2Ylmts7MnjSzBWWu7zazR3N/D5jZtPSbGk7UbY7uj5U1+xfRal/iSULi5s1+lEhJev75+u63VoWtUvfEJF0dOzt9GKwWCtNUa665np7a1bpagTT+PLQyDNX7Y0Erw2pcb6/f2Y0HNbo+otmSvt/T6vpYrqLW1+cHgsqq117zn8+ooia19w4esKvapYKamXVIul7SSZIOlzTPzA4vWu1pSe9wzk2V9AVJS9JuaEjTcrGToFZdqF9Ea4XE3l6/QzJ5sr/83HP1bz96XLV2UuI7PtW63NXqdhmtk6akc83Vqtb19EgXXiiNHVu7m2WtOfHKBZpGK3D1/lgw2OMq4+0cO1a66KJkgTT6wqDrI1opyft92TL/g9GmTeU/e4Mdnl/KduV461Z/GlXUpGy3F0B5UVAbCp/jJBW1oyU96Zz7k3PuNUnLJZ0WX8E594Bz7m+5i7+RNCHdZob1utdJ48cT1LKsWkiMjk877DB/Wk9FrViSY+6iHZ9qk3zX6nYZjVZZ61i5WqJulV1dPhwtXFh50vB67Nw5MJ9dtW6WtebEKw40g63AVTtGsHjHczDHVRa3c9Mmv3MaV6k6VymotfMXyVAz1AbakWq/36P3dBRWyn32kgQ15yp3fZSy/T7fssWfEtSA9rZLVdQkHSDp2djlDblllXxQ0k/KXWFml5jZKjNbtXHjxuStzAAGFGlf0fFpjVbU4pKMChnt+Az2uL0kx8pVE+9WuXixPx8PFtGk4c2y227Jju+IB5o0uyPWCn3lXp/hw/2Oaq1j7cpVEcspF1TLBbVmd30cisGjWdp9oJ1Kr3Wt/0dJPnsdHbWDWm+vPy3+Iagd5guMQmq86yNBDWg/27fvWqM+luuAVXb3y8yOlw9qV5W73jm3xDk3yzk3a9y4cclbmQFTp0pr1gx8CaF9RBW1SZP8zsNgKmq1uifGd3zSPG6v3LYuv7z65VpTA0SThkePJW1JBh2I9PRUHxmzkWkekkzbEH9Ox4zxp1GIjXfxNPODxtQarKVYuSpGq7s+tnvwaLV2muahWLXXutb/oyRdI59+Wnr22eqB/9VX/Wm7V9SiYJnl9gIob1fr+rhB0htjlydIKqlJmNlUSTdJOs05N+TGR5w61b/wf/xj+eujL0VGiMqeqKK2zz7S/vsPrqImVe6eWC6IpXncXvG2brih+uX4fVXbCUs6d1wtSUavrHZdtc9Ote6IlSoI1QZMidaVBp6zUaNKuy9GXTxrta+cStXTZnR9LH4O6pmqIUtaWfmr933TyI8FrZbkx4lK/yOSdI184IHK3ZYjUVArN5iIlO0dJipqwNCwq3V9fFDSwWZ2oJntLukcSXfGVzCziZK+L+lc59wT6TczvHIDijgnrV4tLVggvelN/sv+Bz8I0jxUEQW1vff2E14PpqJWLAtDSidRbSes3mrdmDHluzVF3SwrdY0ya7wLZzzwJB3Eo1q4K7ejOdgd8eHDB6py5UJ71O4pU/zl3/xm4LrnnpOeeir5ACvxIFbuOahnqoZiaYalerZVrhoUH7Qmye0Hc1+13jeNzgnZSklC5o9/LH30o6XrJOkaWfxeKhf4ox872rGixmAiwNAQBbXo/1A7BzU552r+STpZ0hOSnpK0MLfsMkmX5c7fJOlvklbn/lbV2uaRRx7p2smOHc4NG+bciSc697GPOXfSSc5NnOic5FxHh3PveY8//fSnQ7cUxb79bf86rVvn3BlnOHfYYaFb1Hrf/rZznZ3+eYj+Ojv98ka319XlnJk/jW+nq6vwfqK/rq7S25ZbL/ort+1yj6PSfdWzbrV2V/vr6CjfziTPf0eHc2PGlN9u/LVJ+jjq/Ysed612Fr9Pqr329W4rLsnzX+n25e5r+HD//Nb7Hq13W4OV9PlMotpzGG374ov9d1l/f/m27Lln4fqRSp9Xs8JtPP20X37zzYXL77/fL//5zxt/fM22dKlv4x//6Nx//7c//5OfhG4VgHq98Y3OXXihPz98uHNXXRW2PbVUy01Vw1Qz/9otqDnn3Fvf6p+xPfZwbvp0584+27kbb3Ru40Z//cEHO3fmmWHbiFLXX+9ftxdecO4jH3Fun31Ct6h5vvlN5265pfx1ae4QVlPPDnqtUFfc7o6OZCEk2nlMEgrj69YTiGoF3UbaXS4ENnLbRtueJGQnDTGVtlUp3NYK7uXeG7XaXekx1wod8dduzBjndt+9+vNX/Nm6/PLmhNlaar2HOzudO+YYf37LlvLbmDfPuTe/ufRxVXofFr8e69b55cuWFS7/whcKb9Os/z+DEf+uWL3an7/99tCtwle+wr4V6jNunHNXXOHP77WXc//4j2HbUwtBLSV/+5tzPT3O9fWVv/7UU52bMqW1bUJtX/qSf6dv3+7c4sX+/LZtoVuVvp07/T+nqVNDtyS9qkuj1aR6duYrhcJyO+jRDn4jFbTQf5UCUj1hNkkgShq4il/rpBXN4gqOc/WHvHpCZCPhtdrjrPc9Wa/o9azUlpEj/WlPT/nP6dlnO3fooY0/rkcf9df9x38Utim631rPSUhf/rJv29atA4EzZBtb9eNa1v2P/+G/24CkRo1ybv58f378eOcuvTRse2ohqLXI/Pn+y6hSkEMYCxb4X/37+321SXLuqadCtyp999zjH9v48aFbUp9GulE2slPcSPWi0R2lRtrdzL/i8FstjFYLMM1oWz2BJ36bRt8nSR939JzVqr4lve/oORwzZqACWa2Ng1Xr9Vq8uPzn4eijfffwao+r2udh1Sq/zp131n59BhNIB6PS5/ozn/HL+vude+YZ38ZvfCNcG9OstrazyZP95xVIatiwgUORJk507rzzwranFoJai/zbv/lndP360C1B3OWXOzd2rD//05/61+j++8O2qRkuvXRgJ2rnztCtSUeScFDP8UOt+oW6WaEm6XNQqetdFit98VBST4gcbOU1/pxV69ZXK2Q047WuVOVN48eC4cP96eteV/l5PeKI6o+rWrt+/Wu/zlVXJa/U1mswn+NqAehjH3Nu9Gi/3saN/rrrrmusjYOVtXAbSn//wOu1fXvo1qAd7Nzp3y+f/7y/fOihzv3d34VtUy3VglqSUR+R0CGH+NN168K2o9j110uf/WzoVoSzebMf8VHyoz5K6Y78mAW9vdL3v+9HHnROevHF0C1KR6WR9qKpALq6pFtu8Y83ycibrRqls1q7I8OH116neHmlUTmLn4NKUzWUG769klpTLdSj2rZ22638dAkvvijdfHPlef5qzYlXPDJpsWgewWojlVaaviI+MfpuKX+LxrddbkTPpCNhVhrFca+9/Pm//KX87bZt89uu9B42qz5qZjQ8/7XX1p6yppGRNJPMC1htBNBqUxhs2eLfE1L4UR9bPU1EK6fGqMdf/zrwekVzogLVRP+DoqH5R45s71EfCWopOvRQf5q1oHbrrdKXvuR3gHZF8aC2//7+dLBzqWXNffdJGzdKf/d3/vILL4RtT1oq7WxGUwFkdUqEau3+2tf85f/zfwaCxdixftm6deWnMCh+zNXmzKsm6U5eV1f1ACMlD0TRtipNzVBtXq4oWBdPLB+pNCdePORVuq008HzUM31F8cTo9UzsXk25bW/aVHluv0rPWaTSBNe9vf76/fYr34499vDPabn38LBh/vWuFnai9kY7S5XEA2k9Uy/UmhewVpCrFoC2bvVzqEXPg5RuUKsnDLVymogk4Xew2280BMZfr2iqHaCa4rlK2z2olS2zq1o7xQAAIABJREFUteJvKHZ97O/33SY+8pHQLRnQ3+/c3nv7MvCVV4ZuTRhvf7tzc+f68/397TFUa70uvdQPq/2LX/jXeigNKd2uB9RXavc11/jX6OWXB9b9/vf9skceqX7bwap3dMR6BmCJurJV2lbx40o6imAj7U56+2rHx9U7AEh8IJJ419Mko3YOZoqIerrD9fUNvEbnnFP+Mc+Y4dzMmaWvV1eXc6ec4kc9Hmx3zyQjaUbq6daa5H1V7b1wyikDj90538ZTT03ns1jvMWetPEatmd0sB/s4/uu/Bm63atXg21OPdv3u2dVt2ODfL9HxpXPn+v3ALBPHqLXOkUc69+53h27FgKif/e67O7fvvs698kroFrXe1KnOnXbawOWJE50799xw7Unbzp3+GLyzz3buySf9633rraFbhUq++EX/Gr322sCy6NjJX/+6ufdd7xxhjexcJt2xSTovV6V21LNjmeb8cPW0O0nbk0wbkDSk1HrOX355YP0FC8o/5pNPdm7WrPK3v+oq50aMaDxQmjn38Y/XFwzSGpin2jQc0WswZ47/i3R2+kEJ0ghLjYShNINCtSkkaj1ng7mven6QKedf/3XgNvfck81pZhrd/q4eApv1HPzxj/71+ta3/OUTT3TuqKPS2XazENRa6AMfyNbBvtGknVde6Qp+YdiVdHUVjvhzzDHOnXBCsOak7u67/Wt7++1+biTJuX/5l9CtQiWf+Yxzu+1WOOHwypX+dbv77ubff71fjq2u7lULW4PZsUzrcQx2hzs+6mMao5xWC37Fnn12YL1LLim/zokn+pEfy/nUp3ywb2Twls5OP5/RpZfWF3bTGqwlyQAtM2f6OVJrvc+SDvaS5D0bPe5Wh456n7Na2693JNmkITDad5H8XFhZrTLW8/+FET2b+xz8/vd+e9EUIaefnv2pswhqLfTP/+w/qFmZp+tb3/Kv8uOPOzdtmn+zxncQdwX77lvYHfWMM5w7/PBw7Ulb1O0xes+NGuVHL0M2feIT/gsp7sEH/ec0PqT5UDeYL+qQI+I1cwejVsUz6U5wpedhzZqBdd7//vLrvPvd/seschYu9D8yRG2tN4REP5qlUVGrZ8qIpK/P61+frKtqtepc9HpF69UTjOp5H1WrkDXS/bZaW6rdV9L3ZKXXr1aoOfvsge1Hz2u1bVWbbL6VFf9qPRVCj+g52FFTQ/3glVT0ffrDH/rL8+Y59+Y3D367zURQa6Hvftc/q7/7XeiWeJ/7nP9i3bHDuZtu8m1bsSJ0q1qnv9//E1+4cGDZhz/s3D77tK4Nt93WvOMDo26P55wzsOxNb/L/mJBNH/mIc/vtV7gs2oG+7bYwbQql0S/90L9IN7PbUq1tD6ay+MADA+tU6lVwwgnOHXts+es++9ncXkORpDtdkyf7gFjP61dr3STHDCZ9fZIGmsEeU9hogKl2PGhafyGm9Kj22X3b2/yPzIPddr3/M5K8p+OvRz2Psd7u02kazP/OegNpNc18Du6/32/rF7/wly+80LkJEwa/3WYiqLXQww/7ZzUquYb2gQ84N2mSP79tm99BPOOMsG1qpagr4Fe+MrBs8WK/rFVVz/e+19/fb3+b/rbj3R4js2c7d/zx6d8X0vGhDzn3hjcULnv6af863nJLiBa1p899buDLff/9d61uQ5F6f5WOjoXcd9/CQTPijj++8oH3V1/tb1/cK6PcDtwee5S+JnPmOHfccQO3SVr5qFUlSSu0p7XDnSQM1XtfrQhMzTxGMAqgtY5ZK37t993Xue5uv040MFojj6ue4FWpUthIdbvcfQ22mjSYH4oGc99J3guhekXEn5Px4/22ovly43PpZhVBrYWiYPDFL9Z3u698xbn//b/Tb8/RRzv3rncNXF6wwFfYenrSv68s+vOf/etx440Dy26+2S976qnWtOHII/39nXlm+tueP9+5kSMLQ+eZZ6bTtfOll5xbvXrw20Ghv/975w46qHDZCy/498j114dpU7vp7fXHEkU7fffdF7pFYdQbUm67za8zY8bAD3jF3vEO/1fOP/+zv31vb/m2xHe+brqpdJ0PfcjvRKX5mOL3naQKWWnHtr+/dshIo0thvdW4ZlbvkjzHaVTukobbSuHn9NN98D/55PTDapJurIPp4pn0vpIO0lTPiKnl1KpkVfusJH0vJKlmp/E5jz6LUfuL27H33n756NF+UKBm9YJIA0GtxQ44oHDwiiQmTHDuiCPSb8t++zl32WUDl3t6fFD79KfTv68sevxx/y7/7ncHlkW/Kv/qV61pw/77+38SZs6tXZvuts86y3cnirviitKudY1YtMh/OcZHJ8T/b++8o6So0jb+3BmGIahkQSQICMggKIIgIEhwTauCAYVdXVExu+qKysfuqpgVcc0JTBhRVATXjK45kUUJisqQc5I46X5/PNxT1dWVOnfPvL9zOM1Ud1dXV1fd+z73TYlz5pnRQtpU4xs3LjPHlGs88gjP17/+xUe7R7mqEcvq+oQJPF+nnUYjxo0+fbw98m4VS53cdpv3a8aO5XObN3u/PxUr7X4GoVNgOsVXXl7yvFrxeMiMAZ0MwRQ2l8vtvMTyL578LL9/9eszf/CiiyKv93iEstc5ibetQyz/vLx3yQhzDXt/+IUKu31WmDDjWK75sJ5yJ8n2KGdb8RY/oSYNr1NA+/axNb3etAlYsQJYsiR5zVPNfjdtAg4+2NrWogXQvTvwzTfJ+5xsxjTINA2vgfQ2vS4rA9auBS64ACgsBO69N7n7X70aaNIkcluTJvzdnY1yY+X339nsdfXqxPYjRLJ7t9WI02Ca6zob+QrRrF8P/PvfwIABwGWXcduGDZk9pkximoKHaX5uxsODDuL/TfNrO+XlbEzshtnu1wi9pIQNtqtVi36ufXs+/vyz9/v9GlLHg19zbnujZ4PWVuPxmjWBZs2sc+q2LwDIz/duAG8arpuG42Zfzobk+fnux28aXCfa6LpWLTadN9fJY495Xzdu58WPggLrnLVsCTz7LO9Jt327NVIPYtMmYL/9eM3ar/eJE2Pfl5Pycv7mXraXue5iuf7crgNng3cg8vwDVlPwhg1pM5jzr3XwZ/odn73h+Pbt0ccGWN/f+Vk7d7LJvN97/XC717Tm48SJvB7czoGzMbrXvRcv5rhyARFqKaBdOwq1MDcXAMybx8c9e4Dly4NfrzXwv/8F73/JEj62bRu5vagIWLAg3LHlOtu28XG//axtTZvyMR0CZO1aDkJdunDgff55YOXK5O1/zRpLeBoaN+bjunWJ7xsId00K4XETatWqcSIXoRbM6NE0GB5+mAYNULWFWiyY8dAY/Vu2RL+mosJbNIQRanv20JgzAsVOu3Z89BNqXoIkXqHiJ/zcjL+KCmCfffg4aFDkveq1r4oK/tuwAXjmGUt8tWwJvPAC52o3ER0kOmrVoiELuAscuwi87LLIz3X+bReJQfgZxW779hNmTuwCNSx5ebxmpk2LNN6dYtd+bH74CWMnsQjlWrWAF1+Mvg6MiN240RIpF19sfReniNm4MfaF1rw8d4Hjtm/7YkSY82DErPO9boLUDa97zS6W3ISc/RzFu1ATdFy5gAi1FNC+PSfAsMbD3LnW//0mMMPHH3M1+b33/F9nhJrdowYAHTpQQGzaFO74chk3j1qDBjSK0+FRM59x4IHAdddxIrv//uTsW2tvjxpgCa14MUJWhFpycRNqACf5XbvSfzy5xMKFwNNPA1dfzQWnwkJg331FqIVl61aeLyNwN2+Ofk1FReIetcJC9+dat7aMbi/cBIldsMSKn/AL8t7VrBlpXIYRkbF4OO24iQ4/D5xTBDo9ZH4esyC8zotSie/bfJelS8OLNXO97d4dabzb9+X83l77btnSEtZBBAllpyfR+XuZ49pnn2jhZRcpyfAWGTFVXAycfz7v8bw8esOc+y4ttRYjwpwHr/c6BamfVzjoXvMScsab5zUmJUKiXup0IUItBZjwjrDhj/PmWQNAGKH2+ed8nDHD/3VLlvDmad06cnuHDnxcuDDc8eUybkJNKXqh0uFRM96zpk2BVq2As88GnnzS3UCKle3bOZA5PWrJEmriUUsNXkLNaRQK0Zjog+HDrW0NG4pQC8u2bYwuqFePf7st1iUq1Pbs8RZq1atzHPSb54IES6z4Cb8g4VWzZuTiSbJFpJMgkRevCIyVZHs1vQgSP25e2bAha0G/ldd3MWGsYYRyWE9ikEiJ1bNjP0du4qi01PJ+BYV0xvOb2o83yCtsQj69IsDM53udg6DQVDvmegkTDpvM+zbViFBLAWHCO+zMnQv06cOVzjDv+fprPs6Z4/+6X35hfL3TKCwq4mNVEmr20EeA4ibdHjUAGDWKg9ZjjyW+byM0vUIf166Nf99lZcwFAkSoJRs/j5oINX+c9xNAg0WEWji2beOiVf36/NttwShMjpqf0WRCH71o1y54nkumIPETfm7GfGGhZcA5hVqyRWS2kmpBaggSP17GfRhhE/RbeX1Hex5fsoRykPANI5bsYa72cxSrR8z52X4htUF5k06c59we8ulGGOHsxC6knSG4xsM8apS1T3McABfMc/G+FaGWAg46iKsIYTxqJSXMFzv8cOaSBU1gZWXAd9/x/7Nn+792yZLo/DSAF2nNmlUjT23bNt6Y++4bub1p0/R51PLzgUaN+HfnzkCvXsA77yS+b+PxcoY+GqGWiEdt3TprklyxIv79CNFI6GP8rFrFsatuXWubeNTCs3UrF62MUEuFR80v9BGwhFrYHO5k4GVgu+VLjRljPW+Emv1Y0+XVyiTpFKR+57OgwP09YY16v32n8zsGCd8wYZVeuY7xeMTsn+0XUhuUN+lGUMinIYxwdsOIU78Q3N27ef6Ki/nck09y+3vv5eZ9K0ItBeTnMy8sjFBbuJBu6sMOC7fS+OOP9Mh06UJPh5+BsmRJdH4awMn2kEOqjkdt332jDY+mTbkqt317aj9/1SoKKfvKVMeO9HYmipdHrUYNGrKJCDWz77w88aglGwl9jJ9Vq6xVUYMItfAYj5oJffTKUUtGMREv2rUDduzInmqyxrB85hn+PXSo9VzNmjRYE62gm4tkgyAtKIiuHlqzZvpCTZNFPPmHYcMqwwocr5BO8/lBCxnxiNmgXEc/4RyrN8+Oc441/9+9O9RhZx0i1FJE+/bhwhhNzoURasXFnOi8MGGPV17JR6/wR1PMxE2oAcxTqypCzRn2CABnnkmjeMgQCuVUsWpVZJgWQC/nhg2J56kZQ8fpUQPoVUsk9NGIvI4dRaglG/Goxc/KlVbVVoMItfCY8TCVOWphPGpA+NSAdPHHH3y0R1+YthlyX6afrVs5R595ZqTH88EHc8sbYkhV/qFbuKFzoSQopDOR4/Yj1lzHWKqg+uGcY3P9PhahliLat6dHy61PjZ1583hBtWvHfxUVwG+/eb/+66/pQRk8mH97CTWv0vyGoiKKwlR7lDKNWUF20q8f8MQTwPvvs4pUqsJw3AxLY6gk6lVbs4YrjiaMyU6TJsnxqHXvTsHnt3ggxEa6ctQ++MAqx15ZMB41Ow0b0siWazQYMx4WFDAsKRVVH8N41IDsE2pmLtxnH2tbrht4uYxZIBw8mMb7hAn8+/jjM3ZICfPee6xam2zsAsetRUSm8rESyXVMxJsnHjUhFO3a0VMTZIzPnQsceijd+2EmsK+/Zo5T/frMhfPKU/MqzW8wlR9jacydi2zd6i7UAGDECOYjPPcccNNNqfl8L48akLhQM6X53SpjNW6cmFAz7+3WjY/J7P1W1UlH6OPatcAJJ3Biqyxo7X4/mVLzXgnrgoU9wqB+fXePml8xEROOlIhHzRS4yjah9scfnIftIlOEWuZwViU083guLz49/DDwz3+m/nOyIWzVHEcioZPxfo9du6x7FxChJnjQvz8vjn/8w3tS05oetcMP59/GgPeawFavBn7/nUINYJ5akFBzluY3GKGWSwVFbr8duOWW2N7jJ9QACrQRI7jvp55K7Pic7NrFFWunB6BNGw5ayfCoOfPTDE2aJBb6uHo1Dbk2bfi3hD8mh7Iy/kt16OPvv/Nx0aLk7C8b2LaNQtbNowZI+GMQZWU8f2Y8rFcvdR41P6GWlxeucFa62b6dYY/2hS8RapnDzDlOoWYqOeci69ezUFdVWlTKhGiU0EchFK1asbHxBx94NzheuZI37GGH8e+6dVkd0GsC++YbPhqhdsQRNPbdVph++YUrz15JpgcfzNXDXMpTe+45xi3Hgukb5IVSwOOPA0cfDdx5Z3zHtWsXwxmcxotbKXGARkzLlokbKqtX+ws1Y9jGgxGBzZvzb6n8mBxMeJ6bIZvM0MfiYj4mo2hNtmDvSWhHhFo4zDwR5FFLdTERgNEj2RbNsX17ZNgjkPsGXi6zbBltFJODba7bXBdqQG7ZXbmIhD4KobnkEuC004DRo4GZM6OfN4VEjEcN8K/8+PXXNPC6dOHf5tHsx45XaX5DQQGfj9Wjtns38Ouvsb0nGezaxdy9pUtjmzSDPGoAJ4MTTqAXwiSUx8LEifTKffVV5HYvwxLg75wMj5pbIREg8V5qJqzSCDXxqCUHM1GkOvTRCDXjWa8MmIUPL6FWlVap48Ep1OrVy0wxEYDj32+/pbaQ06ZNseUt/vFHdBsXEWqZY9kyLnKaRYPKEPooQi09iFATQqMUw+kaNwaGDYsWAXPn8rFzZ2tbkFDr1s2aBI84go9uBUW8SvPbKSqKfcC4+26GTf70U2zvS5TFixkqqnVsK7FhhBoAdOrER7fvpTVw0UXAp5+6v/eTT/j4ww+R2708aoAV+hNvEZPSUg76fh41IH6hZjxqtWvToBOhlhyM4Zjq0EeT37FqFUuhVwa87ifxqIXDeCLMeFi/vnvo49atvO/dSEbDa4DzXFkZF95SRffusYXKi0ctu1i2LLI6YK6HPu7caS3EiVBLLV6hjyLUBFfq1wdeeomrh1dcEWmYz5vHHDJ7aF67djSSnaJu925g1iwr7BGgId24cXSe2rZtjIMOEmodOlDQxbLq+P77FAnO75Jq7J6/sHk3JSU8b36hjwYj1ObPj36uuJiC+8EHo5+rqAD+9z/39/p51Nq25e9kVthixQgwL4+a2R5PQRGtLY8awOR/EWrJIcijVlqaHC+D8agBmfGApwIj1JyLE6bqqQg1f8KEPm7ezH8mN9VJMj1qQOry1EzkRywLiiLUsgunUDPXba561OzjUy7VBshFvDxquXofi1BLA337AjfeyG7v48ZZ2+fNs/LTDF6l22fP5gRoF2oAvWpOj1pQxUdDUREn3LAheFu3AjNmsPXAZ58BL78c7n3JYMEChkDk5YVfjTIDehiPWsuWnKTdhNqsWXz86KNoUfvjjxyAlYp+76pVnOjdPj9RQ8UIMC+PWiKhj1u3cqAz+27eXIRasvATaiafNBmTSXExBTZQefLUVq7kveT09hQUML9XhJo/To9avXocz+zXmxH1iQi1sB41IHVCzSySxZJbmy2hj9u2VR4veLyUl/O3swu12rV5/eWqR80syu63n3jUUo2z6qNZOBKPmuDLTTcBZ58N3HADBc6OHTSg7PlpgPcEZhpd9+wZub1LF64a2i/AoB5qBlP5Meyg8fnnnKAffRQ48khg5Mj0DZoLFvD7tGoV/nidhokfeXlsk+Am1Ex+4Y4dwBdfRD5nwh7//GeKNruX0ZQSdyufn2iJfr9m1wCw//58jMejZt5j9l2VhdoffwAXXpi89gTpFGoDB/L/lSVPza00v0GaXgfj5lEDIr1qQYt8yfKoNWhAoZgqoWYEWixCLVs8aoMHA+efn77Py0bWrmVorF2oKcVrN9eF2tFH01tY2XvYZhKnR00p/i1CTfAlL49FJ445Bhg+nGF0Wkd71MxKpptQa9PG8pQYunTh6tOPP1rbTLiH16qooX17XsBh3fCffMKLvXdv4LHHGF6Zqv5jThYsoAewQ4fYhVqY0EeA4Y/z50eHdM6aBRxyCI2Pd96JfO6TT2jUnHQSDSG7oHFrdm046CAWMYlXqAV51AoKaAzFI9SMCLR71DZuzN2wgUR47TU2D3311eTsLyj0EUi8oMiWLbwWDz2Ugr2yeNTcml0bRKgF4+ZRAyLz1IxHzautSzLK8wOcd/zysRPFLKysWxc+tD9bPGqLFgHTp/uf48qOs4eaoU6d3A997NuXj5WpdUq24dartEaN3LVhRKilkcJC4K23OEH961/c5vSo1azJwck+gWltNbp2YgqKmDy1zz4D7rmHgtArIdz+WbF4qD7+mKtBNWqwqMmllwKPPGIVRQlDPDdKSQlXejt04L+ff+ZqWxCxhD4CNGw3bowUN1pTqB19NHvjvfuu9VxZGc/3gAHuOW5+HoBq1WgMxWuoGDHlFO524u2l5uZRA6pmif7Jk/norOgZL+nwqBkjp2VLem4ri1DzW/ho0CD9Qu3jj4EpU9L7mYkQ1qPWtKl3W5cwDa/DhD4CXChMtUcNCO8N9/OoJasaaxDl5RSXmzdnX/uCdGLGMDP3GOrUyX2PmhFqEv6YOryEmnjUhFDUrQu89x4N+Pr1o1eMgOiVxkmTaHAPGBD92latOHjNmUPBdOqp3Pb66+GOp0OHcB61desoQuzHcMcdNJBGjgz3Wb/8wte/9lq419vfV15uedRKSqyGvn7EEvoIuIut4mIaMt260Wv2889WeNCcOTR++venyLO/V2t/wxJIrET/mjU8l34GUZMmyfOoAVUv/HHjRhrjeXkUaskonhNGqCWan2IKibRoQW9vZQh9rKjgdZktHrXVq4EzzgCuvTZ9n5koW7dSaJnrzMuj5heJEeRR0zpc6CPA8W/FitTkY9mFWpgFpvJyLpBkOvRxwwaroqZJd6iKGG+T0z7K9dDH/Hyga9fs72G7eDErXXstiJeXp7a1RqKIUBMSpnlzGn7//a97/pIRasbYv/xyetPOPTf6tUox/HH6dPYCq1MH+PBDq2R1EEVF4TxUprKhyXsBONGPGEGvUpjJ9q67OOHF2rTaCEkj1IBwg1w8oY9ApFAz+WlduzIPDbC8aiY/rX9/CvDmza33btnCQcHLowZY3o54Qlz8ml0bGjeOP0etsNASuFVVqL31Fu+LESO4UPLbb4nv00+omfMcZhHCDyPUjEct20r0L17MfNdY2LCBv0W25Khdcw3HlxUr/EvVZxPbtnEsNHOOl0fNrwhVkFAzxlsYj5rJx07FQsLKlZZYDCPUTL6QM/SxoIBGdbqEmn28rqpCrbQUmDCBUUHORdZcDn1cv57jVPXq8fWwTSdvvMFK11735oUX0imQjVRU0KtvLyYC8G8JfRRiomXL6MIghnbtaASsWwdccAFXKCdOtMJOnHTpwhuqrIwizRku4EeHDryog4zDTz7hJG9CLQ29e9NQcWvobae4mFUv99mH1RO3bAl/jAsW0Lho3z42oRZr6GPDhvRC2YXarFmcrDt1Yqhi+/ZWntonnwAdO1rhhybHDfAvzW9o25YDhyk7Hgv28vlemNDHWD1BRgQag85UD6xqQm3yZHqn//53/p2M8Ec/oda+PQ3hRHsUFhfTSN1/f6toTbaU6Nca+OtfgSFDYrsuvZpdGxo2jOxTlErefZdRAe3bc8yN5/7NBNu2RY6FxqNmhNqOHbz3E/GolZTwMaxHDUhN+OOKFZwXzf+DMELN6VED0mvgmWiGRo2qrlCbNIm/2fXXRz+XjtDHG24Arrwy+ftdv56/KxBfD9t0YgSa19g2bx7tn1haO6ULr16l4lETkoqZwEaOpPC67z7/Vc7jj6dYePddFr2IhbDC5+OPgX79uLpo56ij+Bg0qYwdS8P/uee4YjZ1avhjXLCAIsmUuj/ggNR41IBIsQVQqB16qGV4/PnPbHy9eTMrQNpDQTt1YshGaal/s2uDVyuGMJiG1H40aULDNdbqUmvWRIrAGjU4wVQlobZxI73UZ53FSbVu3dQLtRo1aCQnutJq+g/l5VnjRrbkqX3/Pe+pdetiy58MWvgwEQQbNyZ2fEHs2MEIh0MOAe69l9tS2bQ5mWzdGjkW7rcfF/9M6KPxGCfiUTNGUhiPmvmcVBRVWLmSc1udOrkl1IxHbdAgnpdUX8/Zhta8r4qKgBNPjH4+HaGP777LfrHJZsMGS6h59bB95pnsGKvNwp5XfufKlVyUmTcvfccUFq85VoSakFTMKvhLLzGc8ZJL/F9//PFcievePfbP6tDBqkjpFf5YXMwb1y1HrkEDGi1+Qm3VKuDpp1nt8vTTaUSGzaEDrIqP9mMOK9QKC8Ot7ho6deLnlZdbhUS6dbOeP+kkDlAmjNMp1EpLuUIc5AEArN851hVlZ0NqL4ynL9bwR7ewyqrW9Pqtt3gNDBnC+6Nnz9QLNYAe2mR41ExuhzGGsyVP7eGHrf//8EP494XxqAGpD38cM4bnd/x4a6HF3lw8m3F61JSiV8141IJ6qAGWUPMK94zFo1a7Nr2S338f/NpYKCvjGHbggRy3wgi1P/7gozP0EciMR+300/n47bfp+dxs4cMPuVB63XXWtWYn1aGPWvN+Xr48+VU3nR41Zw/bH39kSOETTyT3c+PBz6O2Z49VGOW779J3TGHxmmMl9FFIKqZ0e716FDhueWxOwrzGjTp1gDvvBN58Exg2zJpo7ZhcLHt+mp2ePYFvvvEOZbrvPk6e//d/PM4zz+SAHGZlrKyMOS1uQi0odMppmIShUyfe6EuWcKV80ybmpxn69OGq60MP8bscc4z1nL2giFmJ8vN6NWvGwSTWFbQtW/g7hfGoAbFXfnR61ACG01bWqo///jdw//2R19PkyfTimlDf3r0poOyFF+IhSKgVFfF6cLsPw1JczNBqgCvQ2VKif+1ahgz+5S/8261noRfGYPC65tMh1ObO5XUyYgTHASOGc9WjBnCOMde0Mc4SCX00HoKwi2Md5/1gAAAgAElEQVS9e3ORL5lG8Zo13F+zZuEXmLLJo7bffpxX8vOrXvjjvffyHjdjhJM6dTg2psozsnkzr4WSEnr9k4ldqLlFMk2YwMdMz7M7d1rjrZtQM4sJQHYuJIhHTUgL1aoBd99NY9HPI5MsRo0C/vMfernOPDP6Yv7kExp7HTu6v79XL4ZouBmDGzZwhWjYMKs3z5lnciB8++3gY/v1V3qpnELtjz+Cc0O2bo1PqAE0ImfN4v/tQq16deBPf6JBcsQRVp4HQM9ifj7fu2oVk/WdCa12TGharB41Z1VGL+LxqJWU8Ld07ruyNr3+9VdWL732Wv6rqLDCHocMsRZAevfm4zffJPZ5YTxqZWXxC6vdu/l7G6EGZE+J/gkTeC/fdBPHtVg9avvvz3xRN9Ih1CZM4P18zz38u2ZN3mO56lEDOEYZj9qSJfzbPqY5SWboI8D7atOm5JaiN4tkuepRO+AAVubs0qVqCbXZs5licfXV3kLfLDSkyqtmX3QxLQKSQWkpRaAZp5w9bHftAp5/nv8P204iVdiLZrkdi7G76tTJLY+aCDUh6Ywc6e3BSgX/+AebWL/9NuPj5861wv8+/pghfl5eO9PfzW1SeeABDkKjR1vbevTgBGp6VPlhr/hoCJtX57aCHESHDvyeRqiZQiJ2TPVHZyhoYSEHYONRCyOy4zGinX3OvDDPxyLUjPfNzaO2ZUvs+W7ZzrPP0vgcPpzX6oUXsuKVCXs0dO/OBZREwx937+b15SU4zGJIvOGPxih1CrVMhz6WlnLB5rjjeI907hybUAu6n9Ih1GbMAI480qqWCPA854pQC/Ko/fqrf34akNxiIoC1AJKsPoWAdQ8Yj9ratcEe6mzyqJmxt1cvhoVmcxn0ZDJuHM+/X6qHWWhIVZ6a/V5O5sKkWQwxHjVnD9s33uD82rJl5oWamSvq1nVfDDfHd/LJHDPS3b8yCHOvStVHoVJy2WVMZp0+nat59eqx9Pzq1f6i8ZBDeFM7hdr27WyIffrpkUIrL49etQ8+CF4ZMwOZvUhKWKEWT+hjrVo0VoxQ69Qp2ug49VSen6FDo99vipH4Nbu2064dB7tYSnyH9ag1bMhzHUvoo9e+K2OJ/vJyFrc54QRe97fcwr///vfIsEfAWuFOhlCrUcN70SPRyo/20vyGgw/OfIn+qVM5wZtqap07cxEmrBEadD/Vq8dzmiqjwSTO2/NVAYap50roYxiPml/YIxDc8DpWj1q7dhynUiXUmje3cnr9MFWI3Rb2MuFRAyhid+6MbUEjV1m2jGHRF19MW8IL8/ukQ6gl06NmcrqMUAMic+3Hj+c4fdZZHOuS0bMzXkyu6tFH+wu1M87gY7Z51cSjJlR6zj+fg9VLL7GM9saNNIJOOMH7PXl5rP7oFGovv8wB1a0p7JlnclL/73/9j2fBAuaC2Fc6mzShwRHGoxarUAMssTVzZmTYo6FRI4ZpOFsVmPcuXUovWViPWmlpbKvyxugI8qjl5zM0KxZD0stbl+1CLZ7Qvg8+4KRz4YU08m+6CXjwQRrlw4ZFi6nevRNf4XZrxGnHVH5MVKjZG8W6lej/4gvmwSTDQ1pSQo+5MUbceOQRipqTTuLfnTvzfWHDflet8r+f8vMpOlIl1H74gcd75JGR21u2pEGX7MIDyWb3bh6/l0etpITfI90eNaXoOUqmUDM91Bo0sFqLBIU/Ll9Oj7kJF7eTSY8aUDXCH997jwtnQYXTzHyeytDH2rVpb6RDqC1ezCIiX3zBBtPNmlnpB5liyRKOC4ceynHXea+b++tPf+J4IEIt9YhQE6Jo1ozJvI8/TsGyaZM14XnRqxdFlVmZ1Bp49FHgsMPc+8X17MkV8smTmZPz/vv8zCOPjBQDzoqPACf3MJUfExFqS5bQgHETakHvBXgewnrUgNiExpo1NB7ChHX268dJMKihuSEXPWqffMLz+MYbsb3vmWc4cZ58srXtqqtYFvvmm6Nf37s3DbY5c+I/1iChBjD8Md4S/cXFvD/s96uzRH9FBfNAPv88OQbyl18yp/bll92fnz8f+OwzeuyNR6ZzZz6G8RaUljKxP2jho2HD1Bk4pk+km1Dbsyf2gj3pxhi2zjGjfn2Oc7/9xusiyKOW7Bw1gPfVL78kr3jDihUce+33QZBQKy7mGOfWqzRdQm37dv4zY6/xCFYFoTZnDj1pZlHJi3SEPrZsyYUuN6GmNXDjjbGPz25CraiI98u//sVQ+OHDLZshk+GPJgS6aVOOvc4x1UQ37LMP7Z1cEWoS+ihUeXr14iBmbtpvvqERdvnl7mFeeXl0nb/7LiejE0+kWFu0CDjlFCZ3l5dTjDmFGkChFtR/J54cNSAyJ80Z6hTLe8N61IDYCoqY0vxhKn2ecQYH2s8/D79vpVi4wU7TptyeSEWqRLwOEycyb9KN117j4513hg8ZWb8emDYNOPfcaKOyfXv3HDKTT/Pll+E+w40wQi2Ryo/Fxfyt7N/JWaL/zTctsZkMI3D2bD56TdivvEJvxYUXWtvMOQ4j1Nas4e8aRqilyqM2YwY9NPaQUoBeQiC78tTKyoAXX4xcnDGGrXPhql49nlvzG6bbowZY91WyBMnKlZZAM49BC0z2lhZO0mXguUUz9OpVdYTa4YcHz2npCH086CDaJG5Cbdky4PbbeX/FghmXTC4tYKVwTJsGDB7MOTcbhJoJgTbjrTP80Z4v3KMHx/1siigI8qhlMqw0XkSoCUmhe3dO4mZSeewxDqpeZXYBriDVqsWwyTffpEh44w2GAgwbxpWd3bu9hdqaNZYHz0lFBcVevB41gIakKbkflpYtGToBhPOoNW7MQe/GG1maOIxrPkyza8MJJ9DQCOttWrOGk4lTqFSvzmM1Bk9ZGb0MYVfBJ03i++NZfVuxgiG5biG0FRXMf6pXz6oaFoYXXuBq4QUXhD+OAw5gAngiXqiwHrWystirgQI0JJxiwl6iv6yM11pREa/tZAo1r35YX37JMOEGDaxt1avzHg4j1MI0jwdSL9SOPDLakDTnOpvy1KZM4QKEvWmvn0cN4PcDkudRi0Wode3K6yFZ4Y/Gowbw++6zT/ACk9t9Y0i3ULOP7b168dgyXbI9lZSVcRzo0iX4tekIffTzqJnqpPYw8jAYj5p9DDRCDWDYI5B5oVZSQrFqPGpux7JypXWcPXpQNMczV6UKY0M5i4nUqEGRlovFeUSoCUlh330pcL7+msb75MnAeee5V9EydOnCsJspU4DTTuPkftxxDJl85x1L5HkJNcAKf/zsM37es8/SiNi+nTdlPEKtTRve5G6FRILIy7PEXRiPmlIs3tK7N3DDDfxekyb5r/q4NaT2onZt5gW9+Wa4VS+/RtrNm9Mzd/rpNIqPPJL7DtrvDz9QEG3YwBwEtzDMhx/mc27f+6WXuP3TT6NXxr/7jgbOfffxnJjS6X5ozf6EPXp4t5zwondvGpQvvcTE9/bt+c8YqEGEFWpAfOGPXp4BU130xRfpib79dvYC+/bb2ArZuGGEmlsFsJISigCTb2MnbOXHMM3jARpBqRBqO3YwZ9AZ9ghYxn02edSmT+ej/dz6edQA/ka1a7vnaNkJangdT+hjjRqMXEiGUNM60qOmVHAPyNJSvifTHjW33ONM5qlt2wZccUXqq/otXsxxMYxQS6VHbds22iMHHcRrYd266IVTE8VjL2EfhvXrea/ZF0Dr1OGY1qqVVazNRMqkSqiVlXFeefllFs9yesuKizmfH3ywJcbsrzH3l3nuqKP4mE3hj+ZedQt9tD+fS4hQE5JGr168YSdMoIF22WXx7eeSS+g9MX3M7CtPBlMF8oUXmIfVrx9D4C64AOjb1wpPiyf0MT+f3r6//S2Og4flkQvbA69DBwrTjz7i8Q4bBhx7rPdk4NaQ2o8zzuB7wkz2ft66Dh1o7M+ezdL1I0fyN3rlFe/9bdlCYVe3LgtKzJvHRzsffMCcqfHjoxtoas3+MgcfzP+/9FLk82+9xbC6004DrrmGRqq5brz4/ntOVvZQvLD06cN8pHPOAV59leLg55/5HcIQRqjFW/mxooJC1s0z0LYtjYxbbqFRPHgw79ft2+MvXALw/T//bLWqMJ4Zw5w5/M4mvM1O5840oE3VQS/CCjXjUUt2aMvcuTy3bmHQ++5Lr1SiQu2dd1hhNxmrvW5CLcijNns2F6iCQs9SEfoI8PqYOTNxI2rjRopFe45mUC81UzAhGz1qhx3G8SIThvDkyYyMefPN1H6OCWkPI9QKCvh7pMKjZq+Ya0S787pJRKjZ89MMDz4IPPWUdV8VFDD6IdlCbdMmVqved18uBP71r8CYMdFzsb3pvbEx7EJt61beC0aoHXIIx5RsanztF/pofz6XEKEmJI1evRhuePfdNDrcBFZYxo6lwCgqci/X26oVjYHHH6d4ePBBTtLPPMPB1PQ6i8ejBnCCuvrq+N57+uk0XINWp50ceywNpscfp8F76KHA/fdHrl7v3s1Vv7AeNYDnonr1cOGPfh61Rx/lBPX77xTjY8cypO2f/3Qf/CoqGIJVXMxm6pdfzlDMG2+0JqIVKyh6zO/8wAOR+5g9m6Lq+utpzL3wgmWIa01v7IABfO8ll3DSCPKqPfUUQ27PPjv4fDg591yW8J81i5PfZ59RIPiJVTu7dwcbsfFWfly9moa+m8F58MFcIV66lA2+TbU9ILHV+nnz+DtcdJF7BTDjJfESagCLjfixciXFuJuhY6dhQxrpyW5DYMSnm0cNSE6J/gceoMc4EdEM8N787Tf+Fvbz6uVRM0Jt167gsEfAMna8hE88HjWA10dpqVW0JV7McdnDZIOEmltLCzs1a9ITkeqQqdWreZ3b+/QVFNAYjre4UCJMncrHVIvEOXOsHqRhqFMnNR41N6HmDH80Qm3TJu+0Cze8hNqZZ0b3Yz3wwOQKteXLWWr/gw84Rz7/PBdxevaMThUwIZ0HH8x7uFGjSKFmjsssmuXlcVzMJo+aCDVB8MFUd9y+nUZ5IuTnc0XPq8Jefj6Nm0cf5eBy1VU0vs8/n6EUF13E14Qd/JPJiSdyAHSrIBZEfj5w6aWcmAcMoGexd2/LgAvb7NrOfvsBxx9PoebnbdDa36O2zz4UyGbVPS+PeXXLljF00ckdd7D9wv33UxQoxRW8sjJ+r9JSeg937aKQu+giHqN9cnz+eU7iQ4ZQJC1YYF0TCxdSpA8ezL/r1OF198Yb3lU0166l2PvrX+PzttasyRDbI47gb1VQwMl22jR3gXDPPfQUGsJ41ID4Kj+a8+blUQNYkv9Pf+L/W7XiYkIiQs2EPfbtS7HtzFP76it+jts1Fbby46pVfH9ewGyVqqbXM2bQePK6LxJter12LSuXAokbPMbwGjyY46ARTl4eNRP6CAQXEgF4XXbrxsU4t3DfeD1qZtEg0fBHew81Q7NmFEFelW/dWlrYSVfIlImUcF7nRUXBFY6Tzc6djPAA0iPUOnVyL+Dkxn77pVaomdBHwF2omXsmFq/ahg2RhUT8SKZQW7CA99bKlRRqDzzAebRTJ6aZzJxpNbwH6FGzh0A7j8X8374QctRRHMN37kzOMSeKX9VH+/O5hAg1IWm0bk23/QEHAIMGJb4/pfxXZi+9lIa584Zs0IDGcUkJQ0dykWbNgLffZqjfkiUMC7ntNmviiMWjBtA7uXx5dGianU2bKJ5iEYEDBjBP7Y47rDK+ZWUsOXzzzRREV1xhvb5NG3rgXnuNZfG//JK/1SGHWM2QTThGaSk9VaeeysnxrLN4PbzwAp+fMoWPp55q7f/qqznhjxvnfrwPPcTr4rrrwn/HIIYO5ST19tuR2xcuZH+xSy+1qm6GFWrxVH70MziPOoqCaexYS2gbr1qiQq1xY16PPXpQqNk9nl995Z6fBvA6a9AgnFALE0YcRqiVlMReoWzmTG9vGmB51OINuXz9dR5TYaF3QZawfPwxf4uzz7aq5gLhhFoYj5pSwF13cRx68sno5+P1qDVqxBYbiQo1N0OyWTOeX6+m12ZMTUSovf++fx/BMHhFMxQV8d5ORs/DsEyfzrGqTx8a+6kq3qE1hVqYsEdDnTqpOZ6lS3kP2qsv2oXa1q38jUxP2VgKinh51NxIllD79lt60srKOP/06xf5/LHH8r749FNrm6n4aOaIpk3dPWr2+6tHD441ZtEu0+zezcWOatUit5t5V3LUhCqNUvSsPP10+NWxVBK0Ap/tKMWCKgsWUGjddJPlPYpFTAEUM9WqRYY/as19m5UwtxyJMIwdy5BXIySPOYal8i+4gCGSzryXG26gUfbhhxQxpmhMixb8nhMm0Cj54ANOcCZXsF49irtXXuHk89ZbnCTsk0aTJswvfO45K97e8McfDGk97TSrf10y6NOHE9qkSZHb77yTXt5WrbiKuWULDdmwHjVn5cfrr6dg8Mrp8gvhatGCK8Ddu0du79mTBke8PaxM43eluO+NG62V5t9/p7fILewR4Hs6dw4OfUyWUCsv58LNqFHe+3AWydiyhb+BX5uOli15D8Xbw+3VV/l7DxyYmFCrqKBQGzjQypM153brVhqhTk9XjRqWEAnjUQNo4A0YwII0f/wR+Vy8HjWA18nXXydW6nvFCo779vExqJdacTGNc2eVOEOQUJs5k1EUblVpY8Er99ikEJiKg8lCa46n994b/dy0aRT1N9zA1/kt8BniCQ9dtowenViFWqo8ai1b8vopLORvYRdq5vyfdBIfw3rUtOaYFItQ27gxcc/P3//O3/Crr9wXrHv0YJSMyWkFOBfYF2ycQs0tX7hHDz5mS57arl28Z512h4Q+CsJezjqLk5aQPPbfn+Jk6lQOQHl5VgPqsNSrRwPOhD++8w4N644d+Vz//lZuV6wisGNHirLHHmMvnPnzWVXqqafcjZ/CQnoKr7qKYZF2rrmGxvHEiQx7bNSIYZuGc8+l8f/sszSQjHC18+9/UyCdc06k4TB+PPftZ6jHQ14ePRjvvWflLSxZwnNw2WV8XLmS/9+1K7xHDbDCHydNopdw5kzmQLp52oqL+Vvuu2/4Yzferm++Cf8ew+7dDMk1RpaZsE2olF9+msEINT/j3F5lzI8gofbhhwxdevVVd+/XokU0bF5/3dpmCtP4edQSKdG/YgXwxRe8frp35/l0ip+w/PgjFzYGDmSoa2Gh5a3cts07X9fkRIXxqBnuuouf5bx/jREUj1A7+mguQiQiSFas4EKTfTXdjJV+Qs3LmwZwLAG8hdpNN/Fx0qTEPCFe1XydY4EfP//M8S+M2P3xR84Dt9wSec+UlzM64MQTrXs3TPjjJZdY3qawmDD2WIRaKkMf7YtczhL9Jj+te3eONWGF2pYtFLGxCDUguiJjLOzZw/zhYcMY6eRGQQEXVY1QKy/nd7Iv2DRtyvnWzKMrV3K8sM9h++/PqIJEowGShVfUioQ+CoKQck49lZP199+HH/TtnHEGV8w6d+ZK6oYNNLSuuoqTiQkpNE18Y+HWW2nQtGnDyXfYMP/Xd+vGAjDOAfWoozgR3ncfV3WHDYv0zp50EicKs3rtJtSaNWNY1nffMSQToLC5/36Gfzi9Sslg2DB+hgnHvOsuhn+NHEkBM2YMDbnly8MJtUMOsSo//vIL8/d69aKn8LPP3FsZOA2NMHTtyvMbT/jj/Pmc3I84gn937MhrwEzYX31Fo8qvBULnzvRGOY0erWlYv/MOr81keNSeeoqPy5e7G72vvspjGTHCEl3Gk+DnUUuk6fXkyXw0Qs3efDpWTH7awIEUKkVFkR41r5xMUzY8lsWf7t3pmR43jue7vJzRFPfcw/svnvzcPn34aIpYxIObqA/yqPn1UAP8PWrffMMFmksvpThyVtELS3k5ha/bIlmbNvw9wwi1MWM45plKin5MnswxZseOyCJO339PD7sJOW/fPlioac3z8MUXsYVrz5nDYzD5qmFIZeijn1BbvJi/Q6tW/E3Chj66Nbv2Ixm91ObPp7jq2tX/dcceS3G/bBk/r6QkUqgdeCB/27VrrWNyWzTr2jW7Qh/d5lgJfRQEIS3UqRM8+HoxeLBV2nj8eE4811zD0Jc5czg5z5sXu7EPcCX4999puMSyMu9EKeAf/+C+9uyJbpFQvTqN2u3bKWZMmwYnZ51F79ttt/GYXnqJk0yyvWmGbt34vV95hRP+889TXBnDa/RoegyAcELNVH6cNcvKzXvlFRYyuflmCjbjAdWav+XChf6eAa/P6do1PqFmVsONUKtWjfuye9SOOsrfaLcXFNEaePddrsrXq0fhcPLJvCYOPzz4eOrU4We5CbW1ayn8TaXP996Lfs3UqVaY2bBhVhXC1q0jK/E5ScSjNmkSz1+7dpbXzm1levny4BX26dO5HyO47H3qgjxqrVrFLq5uv51G/lVXUWRddRWv8S+/DC7z70bbtvztx42L36u4YkVkIRGAFWFr1XIXaloHL3D4CbWbb+ai2bhxFK5PPBFfLtm6dRR6bh61ggL+rkEFRTZutELbTXEaL7RmnnC/fiyG9PDDVlGJadN4L5vImB49GNbml4O5YoVVdTaWIkhz5lAIGq9lGFIR+rhrF38D+yJlixa878z3XrSIIqaggGNCWI+ayV2M1aMWJNSWLWOagBtGNAXZCqaw1McfR5bmN5gFMjP2eAm1I46gcI2lEmaqCBJq4lETBCFradSIk4vx0DgT/hs1im1l00m9etEJvPFwxhk0toqKLBFg59xz+ejmTbPz8MM0Ws85h6LmsMMiwyiTiVIsKvLxxyxUkpfH/A5Dfj49lvXrRxuSXhQV0aM0dy5DQY0Iu/lmConRoxkG2bw5Bevvv1vhh7HQqxc9R7GshAM0BurWjTRuevSg8bV+Pb2BfmGPAL9jXh4N3E6d2Erixx/5/R59lN7DDRvChVPn5Xk3vZ44keFHY8bQw+cUasuW8biHD6fx8+23PM8zZviHPQI8B/vtF7tH7bffKMqMeGzYkAagU6hpzQptAwd6Vy4sLeW5OvZYa1unTjSeN27096hdey3PS6wUFXEh5ZVXuFDw/PM8r/Es9BhuuYXHG69nyt7s2qCUd4n+jRtppPstcHgJtS++YGXE//s/VsobOZKG6nPPxX7cQdV8O3QIFkAvvcR7uG7dYKE2fz5/syFDGCq5bRsLLQEUan37WoVmevSgiPG7vu35SV6Vmt2ItZAIwOv4jz+8m67Hg1vF3BYt6GE3OcGLFlkLg61b8z1hcvJSIdQqKlio6+KLo3OxAS7w1asXHB1TVMRrbvr0yNL8BiPUzLGsWuXtUQPCeXJTjYQ+CoKQ0zRpEntFtnRTUMBCIlOmuK/MH3UUjZLrr/ffT506FEdLl9IoueGG+Fb6wzJ0KCfQN95gmwinwXjQQZzcwxYdMCGD111Hz5JBKfYLPOYYGou9e1Po/PILxVus9OpF72UsBhYQWUjE0L079zV+PAVGkFCrVYsr6h99RKH1/PMUMI8/zoquffv6e7OcmKbXdrRm2OPRR9PQOvFEnje712baND4OGkTj9aKLWIJ+2bJgoaZUfCX6X3uNj2edZW3r3j1aqM2YQSNx0SKeHze++47erYEDrW32giJ+HrVBg4JDlb0YO5ZFcxYu5AJKovdX9+4Mbx43Lvbwtm3b+M/NkGzWjN4RJ0E91ABvoXbTTRxPL72Uf/fsybHpgQdiFxGmIqVXIaeiIhrSbi0RAF7jEybQs/+Xv/D69hMRJuzx9NO5gDV4MI/b9K20V9J15p668e23NI5r1w4/jmzYQPEcq1Az13Eyq2Aab7jTowZwDCgr4/hqhFqbNvyNneX73YhVqNWpw3HRT6g99xw91wAXaJzMmhU9NruhFBd3pk9nCGRBQeS8Zc+XKytjZIJbGLr5DU1ObyaR0EdBEIQ0UFTkXZnRVMMMY8D36UNv2oABkQZxKjj0UIqr/HzvEMvatcMbs+edxzYHd94Z/VyNGiyrvG4dc6suuYQrofEYyqb/YSwFRUpLGVbnNLKMUffIIzQEw+QDvvgiDYV582jsJ7KQ4CbUvvjC8iIDFGqlpZFeh6lTKRhN38UHHrCMMr/8NEM8Ta8nTaJhbzcOu3en8Wc8LAAXGwoLGf45Zoz7ivDHH/O379/f2mYPK/XzqCVCo0ZcHNh//+Tt85Zb6MVw683ohzFs3TzWXh61oB5qgLtQ+9//eP+NHh0ZtjdyJAWVEf5hCeNRq6iIrAJrZ8YMeqJHjOA1sH27d/Nwe9ij+d1uvJHeQDNG2oVa584cb4KEWteuFH1hhVo8hUQA6zpOZvijm2A3IcTLljFaobQ00qMGhAt/jDVHTSn/Ev0bNnDRsXdv3n9OoVZSwsWZsCkSxx7LeWTqVH4vewh0o0b8e9UqXqMVFe4LIfvvz3ssG/LUTNVHJxL6KAiCkKVcdx0N2WSEZQbx8MP0drVqlfi+2rVjHpBfq4tkeAibNqWBEkue2sKFXN13hqY2b86+amvW0GgLU4HyiCPoCUrGd3ETahMm0Lg780z+ffTRLEttwh+3bKHRbe/9WKsWPaOXXUYxFUSsHrUFCyhMhw6N3G6ErSliUlpKQTdoEL1My5fTe+pk+nQaZva+aI0b83wYj1oqhFoq6NYNOOUUft9YjHG3Hk+G5s1pbDo9XX5N4g1uQu3WW3nfXHxx5GsHD6bw/s9/wh83YHnUvISaqfzolaf21FO8ZocNs/pl/e9/7q+dP5+Cb8gQa9sRR9Br/+uv9MTax6+CgsjcUyclJTTQjzqKomvu3HBVJ+MVasajFtbj+sMPFFh+xT+WLuX8YPcW2T1qpuKj3aMGhCsosn49f5tY8vD8hNqoUbwvnniCEQdOofbTT/xN3NIG3DBe+F9+ic4vz8ujl3flSv/7C+DnZYNQk9BHQRAEwZP+/aMLoOQCvXrFVrHNWUjEoJTlVQsKe0wFTZrQ4PjnPykWN29muf2//tUylKpXp3Hy3ntWtbqysj+trPEAABkFSURBVOicxw4d2HIiTKn5li1pPIVJpq+oYFjnvvtGC7UuXbiCbcIf33+fwvPcc3nMAweyqp89bPPrr+nRsOenAVafunnz/EMfs5ExY3guH3ww/HuMx8zLo1ZeblWvMxQX08vt5513CrXlyynsL7882iCsVo0Fmr780lsoAdGFOdasYW6ZV6Ghdu34e7rlqW3fzjzBs86iGG/YkL+7V57aa69ZYY92bryRj/YFC0OPHgxrcxsffviBxm+PHrx+t28PJ2DmzKEYiiW0GbCu47AifswYhr77eTmLiynmnd6kwsJIoWY87k2b8rkwHrVYml0bvITal19yIfDaaxnB0a8fj8/uzTfhh2E9as2aWQLUrZfigQdykcMUFPESal278jynszG7GxL6KAiCIFQ6/vY3Gotjx0Y/pzXDL2+/3Uqsnz2bBm7bttGvN0LN9GhLJ6NHM2zr7rspnk46iRO3CXs0nHgiDZyFCxny07hxfIVYDLGU6H/4Ya6CP/AAP9dOrVr0aBih9sILNLxNEZw777TaalRU8Hv27UuD1+ndAbgv4+HIFY8awAWAQYPomfJqt+DECDWvHDX7awymh5qfN9cp1ExlRa9Q6gsv5H0xdGh0XpzWwNVXU3jt2GFt9+qhZj+G1q3dPWqvvUbjeMQIa9uAAay66sxp05r5afawR0P37rwu7UWQDD16cF+miqgdU0jEeNSAcOGP8RQSAaJDH8vK+Fs8+2z0a3/6yWqZ4iec3Sp/KmWV6F+0iItAdevyubw8eh3DetTiEWqrVkUK+tJS5kO2aGH17jvmGD7avWqzZ/McefVPc8Ms8rgJNdP0OoxHTevMFxTxEmoFBfxNxaMmCIIg5BwnnEBj5/bbo/NgnnySuXI33kgjYeRI4PPPmTPlVtJ98GAabab0czpp1oyG6OLFbMI+Z4610m/HVJGcOpUtAU45hcZXvIQt0b94MasEnnwyC864YQqKbN5ML8DQoVb4q71/2QknUJiecQaNM7dw206drKISueRRA3gt7t7NkNUwnt6VK1n1081I8xJqQT3UgGih9vrrDOt1W6QAGFY7dSpfP3gwKwcCNGKvuorVFZcssQQfwEUSr7BHg1flxwkT+Jx9YWTAAJ47ezVGgELr55+9RWbfvu7hyn4FRb79lsZ8s2bM0S0oCBZqW7fyOOIRas7Qx4kTec9ffnn02HXXXVxQOu00jlleRV6WLnWvkGhK9C9aZHnTDGFL9Mcr1EpKIhcpXn+dwvOBB/idAJ7v+vUjhZopJBLLeGbGaud3BPjbmtDHggLvXDsTXZHp8EcvoaYU72URaoIgCEJOYhqQ25tpf/cdjcuTTmII3emn83Vz53obWUVFLEwSNnk+FbRty8qRq1ezgqiTFi14nPfeyzBCt3CvWAjjUSsro+eyVi1WxfTy4nTvzrC/u++mF8O0ozCY/mVffEERPWmStwizt9vIJY8awNCup5+mEfr3v/v38QJoNHu1vjBi7McfI7eHaRJfvTp/q127aKx+9ZWV7+hFhw4MR5wzhx42rbnA8cgj7BN58MEMYTOsWePvUQN4vf78c2SLhvnzKZRGjIi8nvr2paHuDH801R5PO83/s5y0aEEh6SXUjjqKn19YSPHgZ6yvWmV5cJzhumGwhz7u3Env0uGHc+waMcLKj1uyhL/BZZdxMWPrVo5hTkpKeExu14HxqC1eHN2z0zS9DrouN2yIT6gBkeGPU6bwN7CPVXl5kXlqpaX8jrH2Wj35ZOC//3X/PZo25Xi0ZAmvUS8BeMABjBDItFDzKiYC8BqR0EdBEAQhJ2nShMLl009Z/nndOhqkzZoxBK9zZ5aHX7KEeR9XXpnhAw5BvXreIubEE+m1qlUrsqx9PDRsSONg9mwaZm7G29ix9JQ9/ri/UW4KijzwQGQjbENREfPqZs9muKNf2F7HjtbzueZRA5hbOHo0ha1XbzWt+ZoPP7QKaTipV49FZExLBIBG/oYNwU3izUr8rl3Am29ym70Qhxd//jNDVSdNorfr/vspOO+7j97ezz7jvaQ1FxSCPGpFRRQVdi/Offfx2Jx5sXXq0Fi3h/stWMBFluOPj71Kp8k9dXro1q+nWLEX3OnShQLV7R6YNYvX88KFwFtvxZfHag99fPBBiqyHHmKY7BdfWMV27rmHHqCRI/0LrKxYwWP1EmorV7LfnlOotW7NRZ6NG/2Pd/362BetnEJt927e84MGRQulY47hNbFihXeRpyDy8ni9uokwcywzZ3qHPQK8RrKhoIiXRw3gdvGoCYIgCDnLhReypcHIkRRpGzYwRMue8H/QQWwG7RYmk0uY8Mfjj/degQ2LUvSiTJzI1fO6dWmwHnYYixTUrs3w0bPPDm4TUVTE15eUsFm7mxA77jh+XhC1all5J7nmUTPcfjsN1GuuoRizU1rKJuV3301P8Lhx3vsZOpShY/Pn8+8wFR8NNWtS2E2eTE9f2Gt/1ChWYvz2W3p2HnyQv+ff/kaj+LnnmF+2c2ewR8383ib8cfly9pMcMcJdCPTvz8/duZMekUGDeF2NHx/u2J306MFCPXavscmltOd3dulCcWKKTxjefJNjS7VqLIBjbwEQC7Vr89z9/jt/91NO4X6HD2cI36hR9HpOnMhz06QJBUbbtlyEcuLWQ81gSvQD7h41wD/8cedO/kvUozZ9Oq8TZ8EjIDJPLdZCImEwlTCXLvUXauZzFyzIrNfKT6hJ6KMgCIKQ0+TlMZxu+3ZrdTqePJJcoE8fCp4rrkjO/t5/H3j7bXpO/vY3GjitWtF4vOwyiogwRnJ+vmVonXNO4sdlGl/nokcN4DX54osUSCefTO/UdddxAeHUU+nlvfVWeir9WnAMGcJzO2kS/w7TQ81QsyaFwZdfBoc92lGKRS6mT6dH0IjuAw9kjuFzz1l5c2Fy1ACroMj999MTdO217q8fMIBC9vPP2XeyuJjnzCs8NIihQymShg+3cr2+/TbyegXcC4r8/DMXKQ47jOLOHpIbK0px0eHppzlO3XWXtX38eJ6TY4/lo70wSv/+PBf20FHAv+m5/dpw86gBkQVFli1jDqopdBJrs2tDkyb8PkaovfUWv/OAAdGv7dyZ97YRavvs450/GQ/2lgVuza7tHHEErw23ojPJYM8eCmS3olcAf/Mgj1ouhj5Ca52Rf127dtWCIAhC9vHCC1qPG5fpo6i6vPqq1jfckJx93Xyz1oDWS5cmZ3+ZYtUqra+/XuvevbUuLOR3ysvTesKE8Ps47jitW7fWuqJC6/HjuY/i4uD3tW2rdX4+X//TT/F/Bzuvv879jR7Nx48+Cn5Ps2Zan3OO1hs3al27Nv/vxfbtWlerpnXTptz/E08kfsxPP8193X03/z72WK27dIl8zbZtWiul9a23WtuGDOHxrlmT+DForXXLljyOCy6Ifu6hh9yfe/llbp8xI3L7TTfxOtqzJ3pfixbxPTVqaF1eHvncjh187vbb+XdFhdbHH89tAwZovXu31jNn8u+pU2P/jk2aaH3hhVqXlWndqJHWQ4d6v/bkk7Vu107rnj217tMn9s/yY/NmfgdA63vu8X/t0qV83WOPJfcYDG++yf03buz+e+3Zw+fvuMP9/V27an3SSak5tkQBMFN76KU0tIAVBEEQcolkeHKE+DnrrOAQybCcdx7Dr+xhXLnIAQdYK+l79lhlyDt2DL+PoUOZHzZjBj0p+fnBXgKAHrXycnq1TPPpRDnlFFapfPRR/h0U+gjwsxcuZH+/HTvcS+kbatdmSOJXXzGX8ZJLEj/m889nrtS//00P1XffRY8V++5Lj47xqM2cyZDRG2+MbkcRL3Xq0Dtyyy3Rz11xBa+Lk0+O3G7y1D79lE3VAYYXv/gii5FUrx69L3PPtG8fnb9VqxZ/M+NRe/ttFi466SRWkh0+3CoEFKtHDbB6qX31FT1zfgVgjjmGxUAKCpIXIWCoU8fK0QwKfTR98VKVpzZxIr/j2rX0Dg8bFvm8CWuUHDVBEARBEHKCVq0ocBJpP5BtFBYCPXvGJtIAGrvVq7MaYHExDU+/cEmDyWEMU0QkLNWrU+SYMvNBoY8AheLChcx1+/OfrbBWLy6/nOL0oYcSP16A4XhPPsljPeUUFtOwFxIxmIIiAAu9NGjAcNVkcdVVDMt2C+PMy+PiRIMGkdsPOICCy15Q5LHHmGN2553un1OrFguveOWDmhL9u3ezmmdREcMU77qLIbbXX8/XxVMB1wi1t97itWJyat0weWqlpcnNTwP4m5vFjCChFk9BkSVLGMZrmop7sX498M47LMjTtq17cSET1uiVc2wEZ65RiYZuQRAEQRAEd+rWpcH76qvMOQtTSASwDL9Y8tPCYHrpFRREFuzxoqjIqlY5alTw6//yF4rSwsLEjtNO/frMCzT5V26N4rt0YfGJ119nft6//pXcYjYXXkgxFiv9+jH3tqyMFV9vu405pKahvBuTJjEH0o02bSjU7ruPjw8+yN9y1ChWxTWFXxLxqE2Zwpw7t/52hi5drOdjrfgYBiPUwnifu3ZlwR5ns3U3tm7l/XjttRTDHTuy3YJbI/FJk/i7DR/OBYivv47u1yceNUEQBEEQhBxm2DCWw//mm/BCrXFjGpGHHprcYznsMBq2TZv6t1kwGM9Oz55sN5Ap+vdni45OndwLV5iCIhddxHC4yy5L6+F50r8/vYCzZ9OLtnkzW5IEvcerOEfr1iwGc+ed7DFp+pApxfYaQ4ZQpMVTyOfAA4FNmyh4g/reVavGVge1aqWmGq/xpAV51AAKxdJSVlj1Q2uKrt9/p6B/6CF6L++4gy1KVq+OfP3EiQxR7dSJ76tVywobNlRWoSY5aoIgCIIgVAlOPpn5Wzt2hKv4CNAgLC0NJ6Zi5dlnLe9UEF26UNjdcUdqjiUWbrqJ/9wwQm3LFgoWL8M53ZgQweeeY9XI886jWI6XNm0oOCoq6FWzk59Pz+327fH9VkYUKRWulcFdd9Grl58f+2cF0bkz8zpr1w5+rfHoXXAB76+aNelNHT48sm/e2LEM6/zPf9iQHGBY408/sdfeiBHMu1OK22bNYogkQM/4Oeewv+fYsZY3OkioSXl+QRAEQRCELKZ2bcvwDetRa9AgXA5ZPHTq5F523Y199mFxjv79U3MsyaJRIxrpHTtmV2GiJk3olXz8cQqa225LbH/GezVqlHsfNqX8Qxb9MEKtd+9wDcoPP5xevVRwww1W/8EgWre2PF7Ll7NU/+TJ9ACfeir388knwD//yYJJ11wT+f6OHdkf7913KaYBhtrm5zOU13DFFcw3e/ZZa1sYj1ou5qiJR00QBEEQhCrDOecwd6tdu0wfSeVlyhR6PlLh4UmEfv1YkOXaa+PvKWfo1o2VHlMhnM0iQlDYYzrIz/cu0OEkLy9SPAH0Xj/8MAXYYYdZIZpPP+3ubbzySnrb/vEP/l4vvshcNrtg7dyZ4u+xx/i6PXusvnNeQm3ECFblzDUUy/enn27duumZM2dm5LMFQRAEQaiaaM1Qqq5dMx9CKKSX776jJ+3ll5Nb4CQVvPsuMHBgcovBZJJNm4B77mGLh9dei24ibqe4mN7mOnWYBzh5cnQxn1dfZVXTwsLI4iWzZ1vht7mCUmqW1rqb63Mi1ARBEARBEARByBaefZa5bnXrAmvWRAvW0lLg5pv52KAB/7VoARx3XO4twPgJNQl9FARBEARBEAQhaxg+nJ7v1q3dvYoFBd498CoTItQEQRAEQRAEQcgalHJvbF3VkKqPgiAIgiAIgiAIWYYINUEQBEEQBEEQhCxDhJogCIIgCIIgCEKWIUJNEARBEARBEAQhyxChJgiCIAiCIAiCkGWIUBMEQRAEQRAEQcgyRKgJgiAIgiAIgiBkGSLUBEEQBEEQBEEQsgwRaoIgCIIgCIIgCFmGCDVBEARBEARBEIQsI5RQU0qdoJRarJRaopT6P5fnD1FKfaOU2qOUui75hykIgiAIgiAIglB1qBb0AqVUPoBHAfwJwAoAM5RS07TWC2wv2wTgKgCDU3KUgiAIgiAIgiAIVYgwHrXuAJZorX/TWpcAmARgkP0FWut1WusZAEpTcIyCIAiCIAiCIAhVijBC7UAAy21/r9i7LWaUUhcrpWYqpWauX78+nl0IgiAIgiAIgiBUesIINeWyTcfzYVrr8Vrrblrrbo0aNYpnF4IgCIIgCIIgCJWeMEJtBYDmtr+bAViVmsMRBEEQBEEQBEEQwgi1GQDaKqVaKaWqAxgKYFpqD0sQBEEQBEEQBKHqElj1UWtdppS6EsAHAPIBPKO1/kkpdene559QSjUBMBPAfgAqlFLXACjSWm9L4bELgiAIgiAIgiBUSgKFGgBord8F8K5j2xO2/68BQyIFQRAEQRAEQRCEBAnV8FoQBEEQBEEQBEFIHyLUBEEQBEEQBEEQsgwRaoIgCIIgCIIgCFmGCDVBEARBEARBEIQsQ2kdV+/qxD9YqfUAijPy4ZE0BLAh0wdRhZHzn3nkN8gscv4zi5z/zCLnP7PI+c8scv4zS7ac/5Za60ZuT2RMqGULSqmZWutumT6Oqoqc/8wjv0FmkfOfWeT8ZxY5/5lFzn9mkfOfWXLh/EvooyAIgiAIgiAIQpYhQk0QBEEQBEEQBCHLEKEGjM/0AVRx5PxnHvkNMouc/8wi5z+zyPnPLHL+M4uc/8yS9ee/yueoCYIgCIIgCIIgZBviURMEQRAEQRAEQcgyRKgJgiAIgiAIgiBkGVVaqCmlTlBKLVZKLVFK/V+mj6eyo5RqrpT6n1JqoVLqJ6XU1Xu3j1FKrVRKzd3776RMH2tlRSm1VCk1f+95nrl3W32l1EdKqV/2PtbL9HFWRpRS7W3X+Fyl1Dal1DVy/acOpdQzSql1Sqkfbds8r3el1Oi988FipdTxmTnqyoPH+b9XKbVIKfWDUmqKUqru3u0HKaV22e6DJzJ35JUDj/PvOd7I9Z9cPM7/q7Zzv1QpNXfvdrn+k4yPzZlTc0CVzVFTSuUD+BnAnwCsADADwDCt9YKMHlglRil1AIADtNazlVL7ApgFYDCAswBs11qPy+gBVgGUUksBdNNab7BtGwtgk9b67r0LFvW01qMydYxVgb3jz0oAPQCcD7n+U4JSqi+A7QCe11ofuneb6/WulCoC8AqA7gCaApgOoJ3WujxDh5/zeJz/4wB8orUuU0rdAwB7z/9BAP5rXickjsf5HwOX8Uau/+Tjdv4dz98HYKvW+la5/pOPj805HDk0B1Rlj1p3AEu01r9prUsATAIwKMPHVKnRWq/WWs/e+/8/ACwEcGBmj0oAr/uJe/8/ERzIhNQyEMCvWuviTB9IZUZr/TmATY7NXtf7IACTtNZ7tNa/A1gCzhNCnLidf631h1rrsr1/fgugWdoPrIrgcf17Idd/kvE7/0opBS5Sv5LWg6pC+NicOTUHVGWhdiCA5ba/V0BEQ9rYu3rUBcB3ezdduTcU5hkJvUspGsCHSqlZSqmL925rrLVeDXBgA7B/xo6u6jAUkRO0XP/pw+t6lzkh/VwA4D3b362UUnOUUp8ppfpk6qCqAG7jjVz/6aUPgLVa619s2+T6TxEOmzOn5oCqLNSUy7aqGQeaZpRS+wB4A8A1WuttAB4H0AbA4QBWA7gvg4dX2emttT4CwIkArtgbmiGkEaVUdQCnApi8d5Nc/9mBzAlpRCn1LwBlAF7au2k1gBZa6y4ArgXwslJqv0wdXyXGa7yR6z+9DEPkYp1c/ynCxeb0fKnLtozfA1VZqK0A0Nz2dzMAqzJ0LFUGpVQBeMO8pLV+EwC01mu11uVa6woAE5AFrubKitZ61d7HdQCmgOd67d5YbhPTvS5zR1glOBHAbK31WkCu/wzgdb3LnJAmlFLnATgZwF/13kT5veFGG/f+fxaAXwG0y9xRVk58xhu5/tOEUqoagNMBvGq2yfWfGtxsTuTYHFCVhdoMAG2VUq32rnAPBTAtw8dUqdkbk/00gIVa6//Yth9ge9lpAH50vldIHKVU7b0JtVBK1QZwHHiupwE4b+/LzgMwNTNHWGWIWEmV6z/teF3v0wAMVUoVKqVaAWgL4PsMHF+lRil1AoBRAE7VWu+0bW+0t8gOlFKtwfP/W2aOsvLiM97I9Z8+jgWwSGu9wmyQ6z/5eNmcyLE5oFqmDyBT7K04dSWADwDkA3hGa/1Thg+rstMbwLkA5puStAD+CWCYUupw0MW8FMAlmTm8Sk9jAFM4dqEagJe11u8rpWYAeE0pdSGAZQCGZPAYKzVKqVpgpVn7NT5Wrv/UoJR6BUA/AA2VUisA3Azgbrhc71rrn5RSrwFYAIbkXZHpal+5jsf5Hw2gEMBHe8eib7XWlwLoC+BWpVQZgHIAl2qtwxbCEFzwOP/93MYbuf6Tj9v511o/jegcZUCu/1TgZXPm1BxQZcvzC4IgCIIgCIIgZCtVOfRREARBEARBEAQhKxGhJgiCIAiCIAiCkGWIUBMEQRAEQRAEQcgyRKgJgiAIgiAIgiBkGSLUBEEQBEEQBEEQsgwRaoIgCIIgCIIgCFmGCDVBEARBEARBEIQs4/8Bj3OmmWHij3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(epochs[1:], loss[1:], 'bo', label='Training loss')\n",
    "plt.plot(epochs[1:], val_loss[1:], 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
